{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mz0_QVkxCrX3"
   },
   "source": [
    "# COVID-19 Cases Prediction (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS_4-77xHk44"
   },
   "source": [
    "# **Import Some Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k-onQd4JNA5H"
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For data preprocess\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "myseed = 42069  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_path = 'covid.train.csv'  # path to training data\n",
    "tt_path = 'covid.test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtE3b6JEH7rw"
   },
   "source": [
    "# **Some Utilities**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FWMT3uf1NGQp"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    ''' Get device (if GPU is available, use GPU) '''\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def plot_learning_curve(loss_record, title=''):\n",
    "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
    "    total_steps = len(loss_record['train'])\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
    "    figure(figsize=(6, 4))\n",
    "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
    "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
    "    plt.ylim(0.0, 5.)\n",
    "    plt.xlabel('Training steps')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
    "    ''' Plot prediction of your DNN '''\n",
    "    if preds is None or targets is None:\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        for x, y in dv_set:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                preds.append(pred.detach().cpu())\n",
    "                targets.append(y.detach().cpu())\n",
    "        preds = torch.cat(preds, dim=0).numpy()\n",
    "        targets = torch.cat(targets, dim=0).numpy()\n",
    "\n",
    "    figure(figsize=(5, 5))\n",
    "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
    "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
    "    plt.xlim(-0.2, lim)\n",
    "    plt.ylim(-0.2, lim)\n",
    "    plt.xlabel('ground truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.title('Ground Truth v.s. Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39U_XFX6KOoj"
   },
   "source": [
    "# **Preprocess**\n",
    "\n",
    "We have three kinds of datasets:\n",
    "* `train`: for training\n",
    "* `dev`: for validation\n",
    "* `test`: for testing (w/o target value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQ-MdwpLL7Dt"
   },
   "source": [
    "## **Dataset**\n",
    "\n",
    "The `COVID19Dataset` below does:\n",
    "* read `.csv` files\n",
    "* extract features\n",
    "* split `covid.train.csv` into train/dev sets\n",
    "* normalize features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0zlpIp9ANJRU"
   },
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
    "    def __init__(self,\n",
    "                 path,\n",
    "                 mode='train',\n",
    "                 target_only=False):\n",
    "        self.mode = mode\n",
    "\n",
    "        # Read data into numpy arrays\n",
    "        with open(path, 'r') as fp:\n",
    "            data = list(csv.reader(fp))\n",
    "            data = np.array(data[1:])[:, 1:].astype(float)\n",
    "        \n",
    "        if not target_only:\n",
    "            feats = list(range(93))\n",
    "        else:\n",
    "            feats = list(range(40))+ [57,75]\n",
    "            pass\n",
    "\n",
    "        if mode == 'test':\n",
    "            # Testing data\n",
    "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
    "            data = data[:, feats]\n",
    "            self.data = torch.FloatTensor(data)\n",
    "        else:\n",
    "            # Training data (train/dev sets)\n",
    "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
    "            target = data[:, -1]\n",
    "            data = data[:, feats]\n",
    "            \n",
    "            # Splitting training data into train & dev sets\n",
    "            if mode == 'train':\n",
    "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
    "            elif mode == 'dev':\n",
    "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
    "            \n",
    "            # Convert data into PyTorch tensors\n",
    "            self.data = torch.FloatTensor(data[indices])\n",
    "            self.target = torch.FloatTensor(target[indices])\n",
    "\n",
    "        # Normalize features (you may remove this part to see what will happen)\n",
    "        self.data[:, 40:] = \\\n",
    "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
    "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
    "\n",
    "        self.dim = self.data.shape[1]\n",
    "\n",
    "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
    "              .format(mode, len(self.data), self.dim))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample at a time\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            # For training\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            # For testing (no target)\n",
    "            return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlhTlkE7MDo3"
   },
   "source": [
    "## **DataLoader**\n",
    "\n",
    "A `DataLoader` loads data from a given `Dataset` into batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hlhLk5t6MBX3"
   },
   "outputs": [],
   "source": [
    "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
    "    ''' Generates a dataset, then is put into a dataloader. '''\n",
    "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size,\n",
    "        shuffle=(mode == 'train'), drop_last=False,\n",
    "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGuycwR0MeQB"
   },
   "source": [
    "# **Deep Neural Network**\n",
    "\n",
    "`NeuralNet` is an `nn.Module` designed for regression.\n",
    "The DNN consists of 2 fully-connected layers with ReLU activation.\n",
    "This module also included a function `cal_loss` for calculating loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "49-uXYovOAI0"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    ''' A simple fully-connected deep neural network '''\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        return self.criterion(pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvFWVjZ5Nvga"
   },
   "source": [
    "# **Train/Dev/Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAM8QecJOyqn"
   },
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lOqcmYzMO7jB"
   },
   "outputs": [],
   "source": [
    "def train(tr_set, dv_set, model, config, device):\n",
    "    ''' DNN training '''\n",
    "\n",
    "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
    "        model.parameters(), **config['optim_hparas'])\n",
    "\n",
    "    min_mse = 1000.\n",
    "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
    "    early_stop_cnt = 0\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        model.train()                           # set model to training mode\n",
    "        for x, y in tr_set:                     # iterate through the dataloader\n",
    "            optimizer.zero_grad()               # set gradient to zero\n",
    "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
    "            optimizer.step()                    # update model with optimizer\n",
    "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
    "\n",
    "        # After each epoch, test your model on the validation (development) set.\n",
    "        dev_mse = dev(dv_set, model, device)\n",
    "        if dev_mse < min_mse:\n",
    "            # Save model if your model improved\n",
    "            min_mse = dev_mse\n",
    "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
    "                .format(epoch + 1, min_mse))\n",
    "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "\n",
    "        epoch += 1\n",
    "        loss_record['dev'].append(dev_mse)\n",
    "        if early_stop_cnt > config['early_stop']:\n",
    "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
    "            break\n",
    "\n",
    "    print('Finished training after {} epochs'.format(epoch))\n",
    "    return min_mse, loss_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hSd4Bn3O2PL"
   },
   "source": [
    "## **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yrxrD3YsN3U2"
   },
   "outputs": [],
   "source": [
    "def dev(dv_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    total_loss = 0\n",
    "    for x, y in dv_set:                         # iterate through the dataloader\n",
    "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0pdrhQAO41L"
   },
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aSBMRFlYN5tB"
   },
   "outputs": [],
   "source": [
    "def test(tt_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    preds = []\n",
    "    for x in tt_set:                            # iterate through the dataloader\n",
    "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            preds.append(pred.detach().cpu())   # collect prediction\n",
    "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvckkF5dvf0j"
   },
   "source": [
    "# **Setup Hyper-parameters**\n",
    "\n",
    "`config` contains hyper-parameters for training and the path to save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NPXpdumwPjE7"
   },
   "outputs": [],
   "source": [
    "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
    "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
    "target_only = True                   # TODO: Using 40 states & 2 tested_positive features\n",
    "\n",
    "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
    "config = {\n",
    "    'n_epochs': 5000,                # maximum number of epochs\n",
    "    'batch_size': 250,               # mini-batch size for dataloader\n",
    "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
    "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
    "        'lr': 0.0001,                 # learning rate of SGD\n",
    "        'momentum': 0.9,              # momentum for SGD\n",
    "        'weight_decay':1e-5\n",
    "    },\n",
    "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': 'models/model.pth'  # your model will be saved here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j1eOV3TOH-j"
   },
   "source": [
    "# **Load data and model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNrYBMmePLKm",
    "outputId": "fcd4f175-4f7e-4306-f33c-5f8285f11dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 42)\n",
      "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 42)\n",
      "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 42)\n"
     ]
    }
   ],
   "source": [
    "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
    "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n",
    "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FHylSirLP9oh"
   },
   "outputs": [],
   "source": [
    "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sX2B_zgSOPTJ"
   },
   "source": [
    "# **Start Training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GrEbUxazQAAZ",
    "outputId": "f4f3bd74-2d97-4275-b69f-6609976b91f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model (epoch =    1, loss = 316.9156)\n",
      "Saving model (epoch =    2, loss = 303.3374)\n",
      "Saving model (epoch =    3, loss = 285.5539)\n",
      "Saving model (epoch =    4, loss = 262.6192)\n",
      "Saving model (epoch =    5, loss = 232.2632)\n",
      "Saving model (epoch =    6, loss = 191.7604)\n",
      "Saving model (epoch =    7, loss = 141.3373)\n",
      "Saving model (epoch =    8, loss = 88.1166)\n",
      "Saving model (epoch =    9, loss = 44.7452)\n",
      "Saving model (epoch =   10, loss = 21.4559)\n",
      "Saving model (epoch =   11, loss = 13.5662)\n",
      "Saving model (epoch =   12, loss = 10.1762)\n",
      "Saving model (epoch =   13, loss = 7.1145)\n",
      "Saving model (epoch =   14, loss = 4.7069)\n",
      "Saving model (epoch =   15, loss = 3.2240)\n",
      "Saving model (epoch =   16, loss = 2.4218)\n",
      "Saving model (epoch =   17, loss = 2.0268)\n",
      "Saving model (epoch =   18, loss = 1.8656)\n",
      "Saving model (epoch =   19, loss = 1.8052)\n",
      "Saving model (epoch =   20, loss = 1.7814)\n",
      "Saving model (epoch =   21, loss = 1.7631)\n",
      "Saving model (epoch =   22, loss = 1.7442)\n",
      "Saving model (epoch =   23, loss = 1.7231)\n",
      "Saving model (epoch =   24, loss = 1.7025)\n",
      "Saving model (epoch =   25, loss = 1.6830)\n",
      "Saving model (epoch =   26, loss = 1.6643)\n",
      "Saving model (epoch =   27, loss = 1.6463)\n",
      "Saving model (epoch =   28, loss = 1.6303)\n",
      "Saving model (epoch =   29, loss = 1.6154)\n",
      "Saving model (epoch =   30, loss = 1.6013)\n",
      "Saving model (epoch =   31, loss = 1.5877)\n",
      "Saving model (epoch =   32, loss = 1.5732)\n",
      "Saving model (epoch =   33, loss = 1.5618)\n",
      "Saving model (epoch =   34, loss = 1.5489)\n",
      "Saving model (epoch =   35, loss = 1.5375)\n",
      "Saving model (epoch =   36, loss = 1.5268)\n",
      "Saving model (epoch =   37, loss = 1.5172)\n",
      "Saving model (epoch =   38, loss = 1.5068)\n",
      "Saving model (epoch =   39, loss = 1.4971)\n",
      "Saving model (epoch =   40, loss = 1.4886)\n",
      "Saving model (epoch =   41, loss = 1.4799)\n",
      "Saving model (epoch =   42, loss = 1.4709)\n",
      "Saving model (epoch =   43, loss = 1.4627)\n",
      "Saving model (epoch =   44, loss = 1.4547)\n",
      "Saving model (epoch =   45, loss = 1.4473)\n",
      "Saving model (epoch =   46, loss = 1.4399)\n",
      "Saving model (epoch =   47, loss = 1.4321)\n",
      "Saving model (epoch =   48, loss = 1.4259)\n",
      "Saving model (epoch =   49, loss = 1.4201)\n",
      "Saving model (epoch =   50, loss = 1.4133)\n",
      "Saving model (epoch =   51, loss = 1.4072)\n",
      "Saving model (epoch =   52, loss = 1.4021)\n",
      "Saving model (epoch =   53, loss = 1.3963)\n",
      "Saving model (epoch =   54, loss = 1.3904)\n",
      "Saving model (epoch =   55, loss = 1.3850)\n",
      "Saving model (epoch =   56, loss = 1.3806)\n",
      "Saving model (epoch =   57, loss = 1.3751)\n",
      "Saving model (epoch =   58, loss = 1.3695)\n",
      "Saving model (epoch =   59, loss = 1.3644)\n",
      "Saving model (epoch =   60, loss = 1.3596)\n",
      "Saving model (epoch =   61, loss = 1.3550)\n",
      "Saving model (epoch =   62, loss = 1.3505)\n",
      "Saving model (epoch =   63, loss = 1.3470)\n",
      "Saving model (epoch =   64, loss = 1.3426)\n",
      "Saving model (epoch =   65, loss = 1.3377)\n",
      "Saving model (epoch =   66, loss = 1.3344)\n",
      "Saving model (epoch =   67, loss = 1.3306)\n",
      "Saving model (epoch =   68, loss = 1.3270)\n",
      "Saving model (epoch =   69, loss = 1.3224)\n",
      "Saving model (epoch =   70, loss = 1.3196)\n",
      "Saving model (epoch =   71, loss = 1.3159)\n",
      "Saving model (epoch =   72, loss = 1.3124)\n",
      "Saving model (epoch =   73, loss = 1.3095)\n",
      "Saving model (epoch =   74, loss = 1.3056)\n",
      "Saving model (epoch =   75, loss = 1.3021)\n",
      "Saving model (epoch =   76, loss = 1.2993)\n",
      "Saving model (epoch =   77, loss = 1.2966)\n",
      "Saving model (epoch =   78, loss = 1.2933)\n",
      "Saving model (epoch =   79, loss = 1.2902)\n",
      "Saving model (epoch =   80, loss = 1.2875)\n",
      "Saving model (epoch =   81, loss = 1.2842)\n",
      "Saving model (epoch =   82, loss = 1.2813)\n",
      "Saving model (epoch =   83, loss = 1.2793)\n",
      "Saving model (epoch =   84, loss = 1.2762)\n",
      "Saving model (epoch =   85, loss = 1.2734)\n",
      "Saving model (epoch =   86, loss = 1.2709)\n",
      "Saving model (epoch =   87, loss = 1.2685)\n",
      "Saving model (epoch =   88, loss = 1.2656)\n",
      "Saving model (epoch =   89, loss = 1.2627)\n",
      "Saving model (epoch =   90, loss = 1.2604)\n",
      "Saving model (epoch =   91, loss = 1.2578)\n",
      "Saving model (epoch =   92, loss = 1.2556)\n",
      "Saving model (epoch =   93, loss = 1.2530)\n",
      "Saving model (epoch =   94, loss = 1.2506)\n",
      "Saving model (epoch =   95, loss = 1.2489)\n",
      "Saving model (epoch =   96, loss = 1.2479)\n",
      "Saving model (epoch =   97, loss = 1.2449)\n",
      "Saving model (epoch =   98, loss = 1.2420)\n",
      "Saving model (epoch =   99, loss = 1.2403)\n",
      "Saving model (epoch =  100, loss = 1.2386)\n",
      "Saving model (epoch =  101, loss = 1.2363)\n",
      "Saving model (epoch =  102, loss = 1.2345)\n",
      "Saving model (epoch =  103, loss = 1.2323)\n",
      "Saving model (epoch =  104, loss = 1.2306)\n",
      "Saving model (epoch =  105, loss = 1.2289)\n",
      "Saving model (epoch =  106, loss = 1.2272)\n",
      "Saving model (epoch =  107, loss = 1.2253)\n",
      "Saving model (epoch =  108, loss = 1.2235)\n",
      "Saving model (epoch =  109, loss = 1.2211)\n",
      "Saving model (epoch =  110, loss = 1.2200)\n",
      "Saving model (epoch =  111, loss = 1.2185)\n",
      "Saving model (epoch =  112, loss = 1.2170)\n",
      "Saving model (epoch =  113, loss = 1.2152)\n",
      "Saving model (epoch =  114, loss = 1.2131)\n",
      "Saving model (epoch =  115, loss = 1.2123)\n",
      "Saving model (epoch =  116, loss = 1.2108)\n",
      "Saving model (epoch =  117, loss = 1.2094)\n",
      "Saving model (epoch =  118, loss = 1.2073)\n",
      "Saving model (epoch =  119, loss = 1.2056)\n",
      "Saving model (epoch =  120, loss = 1.2044)\n",
      "Saving model (epoch =  121, loss = 1.2030)\n",
      "Saving model (epoch =  122, loss = 1.2019)\n",
      "Saving model (epoch =  123, loss = 1.2003)\n",
      "Saving model (epoch =  124, loss = 1.1990)\n",
      "Saving model (epoch =  125, loss = 1.1974)\n",
      "Saving model (epoch =  126, loss = 1.1964)\n",
      "Saving model (epoch =  127, loss = 1.1945)\n",
      "Saving model (epoch =  128, loss = 1.1927)\n",
      "Saving model (epoch =  129, loss = 1.1913)\n",
      "Saving model (epoch =  130, loss = 1.1903)\n",
      "Saving model (epoch =  131, loss = 1.1885)\n",
      "Saving model (epoch =  132, loss = 1.1873)\n",
      "Saving model (epoch =  133, loss = 1.1860)\n",
      "Saving model (epoch =  134, loss = 1.1848)\n",
      "Saving model (epoch =  135, loss = 1.1832)\n",
      "Saving model (epoch =  136, loss = 1.1814)\n",
      "Saving model (epoch =  137, loss = 1.1804)\n",
      "Saving model (epoch =  138, loss = 1.1797)\n",
      "Saving model (epoch =  139, loss = 1.1787)\n",
      "Saving model (epoch =  140, loss = 1.1770)\n",
      "Saving model (epoch =  141, loss = 1.1763)\n",
      "Saving model (epoch =  142, loss = 1.1743)\n",
      "Saving model (epoch =  143, loss = 1.1734)\n",
      "Saving model (epoch =  144, loss = 1.1722)\n",
      "Saving model (epoch =  145, loss = 1.1705)\n",
      "Saving model (epoch =  146, loss = 1.1691)\n",
      "Saving model (epoch =  147, loss = 1.1681)\n",
      "Saving model (epoch =  148, loss = 1.1675)\n",
      "Saving model (epoch =  149, loss = 1.1661)\n",
      "Saving model (epoch =  150, loss = 1.1648)\n",
      "Saving model (epoch =  151, loss = 1.1634)\n",
      "Saving model (epoch =  152, loss = 1.1621)\n",
      "Saving model (epoch =  153, loss = 1.1607)\n",
      "Saving model (epoch =  154, loss = 1.1604)\n",
      "Saving model (epoch =  155, loss = 1.1593)\n",
      "Saving model (epoch =  156, loss = 1.1577)\n",
      "Saving model (epoch =  157, loss = 1.1561)\n",
      "Saving model (epoch =  158, loss = 1.1552)\n",
      "Saving model (epoch =  159, loss = 1.1537)\n",
      "Saving model (epoch =  160, loss = 1.1531)\n",
      "Saving model (epoch =  161, loss = 1.1519)\n",
      "Saving model (epoch =  162, loss = 1.1512)\n",
      "Saving model (epoch =  163, loss = 1.1501)\n",
      "Saving model (epoch =  164, loss = 1.1486)\n",
      "Saving model (epoch =  165, loss = 1.1477)\n",
      "Saving model (epoch =  166, loss = 1.1465)\n",
      "Saving model (epoch =  167, loss = 1.1454)\n",
      "Saving model (epoch =  168, loss = 1.1448)\n",
      "Saving model (epoch =  169, loss = 1.1437)\n",
      "Saving model (epoch =  170, loss = 1.1427)\n",
      "Saving model (epoch =  171, loss = 1.1418)\n",
      "Saving model (epoch =  172, loss = 1.1407)\n",
      "Saving model (epoch =  173, loss = 1.1400)\n",
      "Saving model (epoch =  174, loss = 1.1384)\n",
      "Saving model (epoch =  175, loss = 1.1374)\n",
      "Saving model (epoch =  176, loss = 1.1365)\n",
      "Saving model (epoch =  177, loss = 1.1359)\n",
      "Saving model (epoch =  178, loss = 1.1345)\n",
      "Saving model (epoch =  179, loss = 1.1340)\n",
      "Saving model (epoch =  180, loss = 1.1327)\n",
      "Saving model (epoch =  181, loss = 1.1319)\n",
      "Saving model (epoch =  182, loss = 1.1314)\n",
      "Saving model (epoch =  183, loss = 1.1305)\n",
      "Saving model (epoch =  184, loss = 1.1299)\n",
      "Saving model (epoch =  185, loss = 1.1290)\n",
      "Saving model (epoch =  186, loss = 1.1274)\n",
      "Saving model (epoch =  187, loss = 1.1274)\n",
      "Saving model (epoch =  188, loss = 1.1259)\n",
      "Saving model (epoch =  189, loss = 1.1252)\n",
      "Saving model (epoch =  190, loss = 1.1245)\n",
      "Saving model (epoch =  191, loss = 1.1237)\n",
      "Saving model (epoch =  192, loss = 1.1225)\n",
      "Saving model (epoch =  193, loss = 1.1221)\n",
      "Saving model (epoch =  194, loss = 1.1212)\n",
      "Saving model (epoch =  195, loss = 1.1198)\n",
      "Saving model (epoch =  196, loss = 1.1192)\n",
      "Saving model (epoch =  197, loss = 1.1187)\n",
      "Saving model (epoch =  198, loss = 1.1178)\n",
      "Saving model (epoch =  199, loss = 1.1173)\n",
      "Saving model (epoch =  200, loss = 1.1164)\n",
      "Saving model (epoch =  201, loss = 1.1158)\n",
      "Saving model (epoch =  202, loss = 1.1143)\n",
      "Saving model (epoch =  203, loss = 1.1141)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model (epoch =  204, loss = 1.1125)\n",
      "Saving model (epoch =  205, loss = 1.1118)\n",
      "Saving model (epoch =  206, loss = 1.1111)\n",
      "Saving model (epoch =  207, loss = 1.1100)\n",
      "Saving model (epoch =  208, loss = 1.1091)\n",
      "Saving model (epoch =  209, loss = 1.1088)\n",
      "Saving model (epoch =  210, loss = 1.1083)\n",
      "Saving model (epoch =  211, loss = 1.1074)\n",
      "Saving model (epoch =  212, loss = 1.1065)\n",
      "Saving model (epoch =  213, loss = 1.1051)\n",
      "Saving model (epoch =  214, loss = 1.1045)\n",
      "Saving model (epoch =  215, loss = 1.1044)\n",
      "Saving model (epoch =  216, loss = 1.1038)\n",
      "Saving model (epoch =  217, loss = 1.1028)\n",
      "Saving model (epoch =  218, loss = 1.1016)\n",
      "Saving model (epoch =  219, loss = 1.1007)\n",
      "Saving model (epoch =  220, loss = 1.1000)\n",
      "Saving model (epoch =  221, loss = 1.0997)\n",
      "Saving model (epoch =  223, loss = 1.0990)\n",
      "Saving model (epoch =  224, loss = 1.0983)\n",
      "Saving model (epoch =  225, loss = 1.0971)\n",
      "Saving model (epoch =  226, loss = 1.0962)\n",
      "Saving model (epoch =  228, loss = 1.0955)\n",
      "Saving model (epoch =  229, loss = 1.0943)\n",
      "Saving model (epoch =  230, loss = 1.0932)\n",
      "Saving model (epoch =  232, loss = 1.0923)\n",
      "Saving model (epoch =  233, loss = 1.0920)\n",
      "Saving model (epoch =  234, loss = 1.0911)\n",
      "Saving model (epoch =  235, loss = 1.0904)\n",
      "Saving model (epoch =  236, loss = 1.0899)\n",
      "Saving model (epoch =  237, loss = 1.0893)\n",
      "Saving model (epoch =  238, loss = 1.0893)\n",
      "Saving model (epoch =  239, loss = 1.0880)\n",
      "Saving model (epoch =  241, loss = 1.0875)\n",
      "Saving model (epoch =  242, loss = 1.0864)\n",
      "Saving model (epoch =  243, loss = 1.0852)\n",
      "Saving model (epoch =  244, loss = 1.0852)\n",
      "Saving model (epoch =  245, loss = 1.0844)\n",
      "Saving model (epoch =  246, loss = 1.0829)\n",
      "Saving model (epoch =  247, loss = 1.0825)\n",
      "Saving model (epoch =  248, loss = 1.0822)\n",
      "Saving model (epoch =  250, loss = 1.0815)\n",
      "Saving model (epoch =  251, loss = 1.0804)\n",
      "Saving model (epoch =  252, loss = 1.0800)\n",
      "Saving model (epoch =  253, loss = 1.0794)\n",
      "Saving model (epoch =  254, loss = 1.0791)\n",
      "Saving model (epoch =  255, loss = 1.0784)\n",
      "Saving model (epoch =  257, loss = 1.0773)\n",
      "Saving model (epoch =  258, loss = 1.0767)\n",
      "Saving model (epoch =  259, loss = 1.0757)\n",
      "Saving model (epoch =  261, loss = 1.0745)\n",
      "Saving model (epoch =  262, loss = 1.0740)\n",
      "Saving model (epoch =  263, loss = 1.0740)\n",
      "Saving model (epoch =  264, loss = 1.0731)\n",
      "Saving model (epoch =  265, loss = 1.0727)\n",
      "Saving model (epoch =  266, loss = 1.0721)\n",
      "Saving model (epoch =  267, loss = 1.0713)\n",
      "Saving model (epoch =  268, loss = 1.0709)\n",
      "Saving model (epoch =  269, loss = 1.0700)\n",
      "Saving model (epoch =  270, loss = 1.0700)\n",
      "Saving model (epoch =  271, loss = 1.0696)\n",
      "Saving model (epoch =  272, loss = 1.0692)\n",
      "Saving model (epoch =  273, loss = 1.0679)\n",
      "Saving model (epoch =  274, loss = 1.0678)\n",
      "Saving model (epoch =  275, loss = 1.0674)\n",
      "Saving model (epoch =  276, loss = 1.0671)\n",
      "Saving model (epoch =  277, loss = 1.0666)\n",
      "Saving model (epoch =  278, loss = 1.0664)\n",
      "Saving model (epoch =  279, loss = 1.0653)\n",
      "Saving model (epoch =  280, loss = 1.0644)\n",
      "Saving model (epoch =  281, loss = 1.0641)\n",
      "Saving model (epoch =  282, loss = 1.0640)\n",
      "Saving model (epoch =  283, loss = 1.0639)\n",
      "Saving model (epoch =  284, loss = 1.0630)\n",
      "Saving model (epoch =  285, loss = 1.0624)\n",
      "Saving model (epoch =  287, loss = 1.0612)\n",
      "Saving model (epoch =  288, loss = 1.0609)\n",
      "Saving model (epoch =  289, loss = 1.0603)\n",
      "Saving model (epoch =  290, loss = 1.0595)\n",
      "Saving model (epoch =  293, loss = 1.0586)\n",
      "Saving model (epoch =  294, loss = 1.0579)\n",
      "Saving model (epoch =  295, loss = 1.0571)\n",
      "Saving model (epoch =  297, loss = 1.0569)\n",
      "Saving model (epoch =  298, loss = 1.0563)\n",
      "Saving model (epoch =  299, loss = 1.0557)\n",
      "Saving model (epoch =  300, loss = 1.0554)\n",
      "Saving model (epoch =  301, loss = 1.0544)\n",
      "Saving model (epoch =  302, loss = 1.0536)\n",
      "Saving model (epoch =  303, loss = 1.0533)\n",
      "Saving model (epoch =  304, loss = 1.0530)\n",
      "Saving model (epoch =  306, loss = 1.0529)\n",
      "Saving model (epoch =  307, loss = 1.0527)\n",
      "Saving model (epoch =  308, loss = 1.0519)\n",
      "Saving model (epoch =  309, loss = 1.0507)\n",
      "Saving model (epoch =  310, loss = 1.0502)\n",
      "Saving model (epoch =  311, loss = 1.0498)\n",
      "Saving model (epoch =  312, loss = 1.0497)\n",
      "Saving model (epoch =  314, loss = 1.0492)\n",
      "Saving model (epoch =  316, loss = 1.0483)\n",
      "Saving model (epoch =  317, loss = 1.0477)\n",
      "Saving model (epoch =  318, loss = 1.0476)\n",
      "Saving model (epoch =  319, loss = 1.0473)\n",
      "Saving model (epoch =  320, loss = 1.0468)\n",
      "Saving model (epoch =  321, loss = 1.0463)\n",
      "Saving model (epoch =  323, loss = 1.0461)\n",
      "Saving model (epoch =  325, loss = 1.0450)\n",
      "Saving model (epoch =  326, loss = 1.0440)\n",
      "Saving model (epoch =  327, loss = 1.0438)\n",
      "Saving model (epoch =  328, loss = 1.0431)\n",
      "Saving model (epoch =  329, loss = 1.0429)\n",
      "Saving model (epoch =  330, loss = 1.0426)\n",
      "Saving model (epoch =  331, loss = 1.0417)\n",
      "Saving model (epoch =  332, loss = 1.0409)\n",
      "Saving model (epoch =  336, loss = 1.0404)\n",
      "Saving model (epoch =  337, loss = 1.0401)\n",
      "Saving model (epoch =  338, loss = 1.0393)\n",
      "Saving model (epoch =  340, loss = 1.0391)\n",
      "Saving model (epoch =  341, loss = 1.0382)\n",
      "Saving model (epoch =  342, loss = 1.0382)\n",
      "Saving model (epoch =  343, loss = 1.0380)\n",
      "Saving model (epoch =  344, loss = 1.0377)\n",
      "Saving model (epoch =  345, loss = 1.0368)\n",
      "Saving model (epoch =  346, loss = 1.0365)\n",
      "Saving model (epoch =  347, loss = 1.0364)\n",
      "Saving model (epoch =  348, loss = 1.0362)\n",
      "Saving model (epoch =  349, loss = 1.0360)\n",
      "Saving model (epoch =  350, loss = 1.0354)\n",
      "Saving model (epoch =  351, loss = 1.0345)\n",
      "Saving model (epoch =  352, loss = 1.0341)\n",
      "Saving model (epoch =  353, loss = 1.0338)\n",
      "Saving model (epoch =  355, loss = 1.0336)\n",
      "Saving model (epoch =  356, loss = 1.0325)\n",
      "Saving model (epoch =  359, loss = 1.0324)\n",
      "Saving model (epoch =  360, loss = 1.0318)\n",
      "Saving model (epoch =  361, loss = 1.0312)\n",
      "Saving model (epoch =  362, loss = 1.0311)\n",
      "Saving model (epoch =  363, loss = 1.0301)\n",
      "Saving model (epoch =  367, loss = 1.0290)\n",
      "Saving model (epoch =  368, loss = 1.0290)\n",
      "Saving model (epoch =  369, loss = 1.0285)\n",
      "Saving model (epoch =  370, loss = 1.0281)\n",
      "Saving model (epoch =  371, loss = 1.0275)\n",
      "Saving model (epoch =  372, loss = 1.0272)\n",
      "Saving model (epoch =  373, loss = 1.0271)\n",
      "Saving model (epoch =  374, loss = 1.0265)\n",
      "Saving model (epoch =  376, loss = 1.0257)\n",
      "Saving model (epoch =  378, loss = 1.0255)\n",
      "Saving model (epoch =  380, loss = 1.0254)\n",
      "Saving model (epoch =  381, loss = 1.0246)\n",
      "Saving model (epoch =  383, loss = 1.0245)\n",
      "Saving model (epoch =  384, loss = 1.0237)\n",
      "Saving model (epoch =  386, loss = 1.0236)\n",
      "Saving model (epoch =  387, loss = 1.0223)\n",
      "Saving model (epoch =  388, loss = 1.0220)\n",
      "Saving model (epoch =  389, loss = 1.0220)\n",
      "Saving model (epoch =  393, loss = 1.0218)\n",
      "Saving model (epoch =  394, loss = 1.0213)\n",
      "Saving model (epoch =  395, loss = 1.0207)\n",
      "Saving model (epoch =  396, loss = 1.0198)\n",
      "Saving model (epoch =  397, loss = 1.0194)\n",
      "Saving model (epoch =  400, loss = 1.0194)\n",
      "Saving model (epoch =  401, loss = 1.0190)\n",
      "Saving model (epoch =  402, loss = 1.0190)\n",
      "Saving model (epoch =  403, loss = 1.0183)\n",
      "Saving model (epoch =  406, loss = 1.0173)\n",
      "Saving model (epoch =  407, loss = 1.0166)\n",
      "Saving model (epoch =  411, loss = 1.0160)\n",
      "Saving model (epoch =  412, loss = 1.0158)\n",
      "Saving model (epoch =  415, loss = 1.0154)\n",
      "Saving model (epoch =  416, loss = 1.0148)\n",
      "Saving model (epoch =  418, loss = 1.0143)\n",
      "Saving model (epoch =  419, loss = 1.0142)\n",
      "Saving model (epoch =  420, loss = 1.0136)\n",
      "Saving model (epoch =  422, loss = 1.0135)\n",
      "Saving model (epoch =  424, loss = 1.0131)\n",
      "Saving model (epoch =  425, loss = 1.0130)\n",
      "Saving model (epoch =  426, loss = 1.0125)\n",
      "Saving model (epoch =  427, loss = 1.0125)\n",
      "Saving model (epoch =  428, loss = 1.0121)\n",
      "Saving model (epoch =  429, loss = 1.0118)\n",
      "Saving model (epoch =  430, loss = 1.0115)\n",
      "Saving model (epoch =  432, loss = 1.0109)\n",
      "Saving model (epoch =  433, loss = 1.0107)\n",
      "Saving model (epoch =  434, loss = 1.0105)\n",
      "Saving model (epoch =  436, loss = 1.0103)\n",
      "Saving model (epoch =  437, loss = 1.0093)\n",
      "Saving model (epoch =  438, loss = 1.0089)\n",
      "Saving model (epoch =  440, loss = 1.0088)\n",
      "Saving model (epoch =  441, loss = 1.0085)\n",
      "Saving model (epoch =  442, loss = 1.0082)\n",
      "Saving model (epoch =  445, loss = 1.0078)\n",
      "Saving model (epoch =  447, loss = 1.0074)\n",
      "Saving model (epoch =  448, loss = 1.0071)\n",
      "Saving model (epoch =  449, loss = 1.0070)\n",
      "Saving model (epoch =  450, loss = 1.0063)\n",
      "Saving model (epoch =  452, loss = 1.0062)\n",
      "Saving model (epoch =  453, loss = 1.0061)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model (epoch =  454, loss = 1.0058)\n",
      "Saving model (epoch =  455, loss = 1.0055)\n",
      "Saving model (epoch =  458, loss = 1.0054)\n",
      "Saving model (epoch =  459, loss = 1.0047)\n",
      "Saving model (epoch =  460, loss = 1.0044)\n",
      "Saving model (epoch =  461, loss = 1.0041)\n",
      "Saving model (epoch =  462, loss = 1.0041)\n",
      "Saving model (epoch =  464, loss = 1.0037)\n",
      "Saving model (epoch =  465, loss = 1.0031)\n",
      "Saving model (epoch =  467, loss = 1.0031)\n",
      "Saving model (epoch =  468, loss = 1.0027)\n",
      "Saving model (epoch =  473, loss = 1.0023)\n",
      "Saving model (epoch =  474, loss = 1.0013)\n",
      "Saving model (epoch =  476, loss = 1.0007)\n",
      "Saving model (epoch =  481, loss = 1.0004)\n",
      "Saving model (epoch =  484, loss = 1.0002)\n",
      "Saving model (epoch =  485, loss = 0.9994)\n",
      "Saving model (epoch =  486, loss = 0.9990)\n",
      "Saving model (epoch =  487, loss = 0.9987)\n",
      "Saving model (epoch =  492, loss = 0.9981)\n",
      "Saving model (epoch =  493, loss = 0.9977)\n",
      "Saving model (epoch =  495, loss = 0.9972)\n",
      "Saving model (epoch =  498, loss = 0.9972)\n",
      "Saving model (epoch =  499, loss = 0.9963)\n",
      "Saving model (epoch =  506, loss = 0.9959)\n",
      "Saving model (epoch =  507, loss = 0.9958)\n",
      "Saving model (epoch =  508, loss = 0.9957)\n",
      "Saving model (epoch =  509, loss = 0.9956)\n",
      "Saving model (epoch =  510, loss = 0.9949)\n",
      "Saving model (epoch =  511, loss = 0.9945)\n",
      "Saving model (epoch =  515, loss = 0.9941)\n",
      "Saving model (epoch =  517, loss = 0.9935)\n",
      "Saving model (epoch =  518, loss = 0.9933)\n",
      "Saving model (epoch =  522, loss = 0.9931)\n",
      "Saving model (epoch =  523, loss = 0.9929)\n",
      "Saving model (epoch =  524, loss = 0.9923)\n",
      "Saving model (epoch =  528, loss = 0.9922)\n",
      "Saving model (epoch =  529, loss = 0.9919)\n",
      "Saving model (epoch =  531, loss = 0.9918)\n",
      "Saving model (epoch =  532, loss = 0.9913)\n",
      "Saving model (epoch =  533, loss = 0.9911)\n",
      "Saving model (epoch =  534, loss = 0.9911)\n",
      "Saving model (epoch =  536, loss = 0.9907)\n",
      "Saving model (epoch =  539, loss = 0.9902)\n",
      "Saving model (epoch =  544, loss = 0.9901)\n",
      "Saving model (epoch =  545, loss = 0.9895)\n",
      "Saving model (epoch =  547, loss = 0.9893)\n",
      "Saving model (epoch =  549, loss = 0.9892)\n",
      "Saving model (epoch =  550, loss = 0.9886)\n",
      "Saving model (epoch =  551, loss = 0.9886)\n",
      "Saving model (epoch =  552, loss = 0.9886)\n",
      "Saving model (epoch =  553, loss = 0.9884)\n",
      "Saving model (epoch =  554, loss = 0.9882)\n",
      "Saving model (epoch =  558, loss = 0.9877)\n",
      "Saving model (epoch =  559, loss = 0.9875)\n",
      "Saving model (epoch =  563, loss = 0.9874)\n",
      "Saving model (epoch =  564, loss = 0.9871)\n",
      "Saving model (epoch =  565, loss = 0.9863)\n",
      "Saving model (epoch =  571, loss = 0.9854)\n",
      "Saving model (epoch =  576, loss = 0.9853)\n",
      "Saving model (epoch =  581, loss = 0.9851)\n",
      "Saving model (epoch =  583, loss = 0.9845)\n",
      "Saving model (epoch =  584, loss = 0.9844)\n",
      "Saving model (epoch =  585, loss = 0.9840)\n",
      "Saving model (epoch =  586, loss = 0.9840)\n",
      "Saving model (epoch =  590, loss = 0.9840)\n",
      "Saving model (epoch =  591, loss = 0.9835)\n",
      "Saving model (epoch =  592, loss = 0.9834)\n",
      "Saving model (epoch =  597, loss = 0.9831)\n",
      "Saving model (epoch =  601, loss = 0.9830)\n",
      "Saving model (epoch =  602, loss = 0.9829)\n",
      "Saving model (epoch =  603, loss = 0.9825)\n",
      "Saving model (epoch =  604, loss = 0.9822)\n",
      "Saving model (epoch =  608, loss = 0.9812)\n",
      "Saving model (epoch =  615, loss = 0.9806)\n",
      "Saving model (epoch =  623, loss = 0.9806)\n",
      "Saving model (epoch =  624, loss = 0.9799)\n",
      "Saving model (epoch =  631, loss = 0.9798)\n",
      "Saving model (epoch =  632, loss = 0.9794)\n",
      "Saving model (epoch =  634, loss = 0.9793)\n",
      "Saving model (epoch =  635, loss = 0.9790)\n",
      "Saving model (epoch =  640, loss = 0.9789)\n",
      "Saving model (epoch =  642, loss = 0.9788)\n",
      "Saving model (epoch =  645, loss = 0.9782)\n",
      "Saving model (epoch =  646, loss = 0.9781)\n",
      "Saving model (epoch =  647, loss = 0.9780)\n",
      "Saving model (epoch =  655, loss = 0.9776)\n",
      "Saving model (epoch =  659, loss = 0.9774)\n",
      "Saving model (epoch =  660, loss = 0.9773)\n",
      "Saving model (epoch =  661, loss = 0.9772)\n",
      "Saving model (epoch =  663, loss = 0.9772)\n",
      "Saving model (epoch =  664, loss = 0.9768)\n",
      "Saving model (epoch =  667, loss = 0.9761)\n",
      "Saving model (epoch =  671, loss = 0.9760)\n",
      "Saving model (epoch =  673, loss = 0.9760)\n",
      "Saving model (epoch =  679, loss = 0.9759)\n",
      "Saving model (epoch =  680, loss = 0.9755)\n",
      "Saving model (epoch =  681, loss = 0.9753)\n",
      "Saving model (epoch =  687, loss = 0.9748)\n",
      "Saving model (epoch =  688, loss = 0.9748)\n",
      "Saving model (epoch =  694, loss = 0.9742)\n",
      "Saving model (epoch =  701, loss = 0.9740)\n",
      "Saving model (epoch =  702, loss = 0.9737)\n",
      "Saving model (epoch =  711, loss = 0.9734)\n",
      "Saving model (epoch =  712, loss = 0.9732)\n",
      "Saving model (epoch =  718, loss = 0.9731)\n",
      "Saving model (epoch =  720, loss = 0.9731)\n",
      "Saving model (epoch =  721, loss = 0.9727)\n",
      "Saving model (epoch =  724, loss = 0.9725)\n",
      "Saving model (epoch =  728, loss = 0.9724)\n",
      "Saving model (epoch =  729, loss = 0.9722)\n",
      "Saving model (epoch =  731, loss = 0.9722)\n",
      "Saving model (epoch =  734, loss = 0.9720)\n",
      "Saving model (epoch =  739, loss = 0.9713)\n",
      "Saving model (epoch =  740, loss = 0.9713)\n",
      "Saving model (epoch =  741, loss = 0.9711)\n",
      "Saving model (epoch =  748, loss = 0.9708)\n",
      "Saving model (epoch =  760, loss = 0.9706)\n",
      "Saving model (epoch =  764, loss = 0.9705)\n",
      "Saving model (epoch =  768, loss = 0.9702)\n",
      "Saving model (epoch =  770, loss = 0.9700)\n",
      "Saving model (epoch =  772, loss = 0.9698)\n",
      "Saving model (epoch =  775, loss = 0.9695)\n",
      "Saving model (epoch =  778, loss = 0.9694)\n",
      "Saving model (epoch =  782, loss = 0.9686)\n",
      "Saving model (epoch =  792, loss = 0.9685)\n",
      "Saving model (epoch =  806, loss = 0.9683)\n",
      "Saving model (epoch =  808, loss = 0.9682)\n",
      "Saving model (epoch =  809, loss = 0.9682)\n",
      "Saving model (epoch =  815, loss = 0.9680)\n",
      "Saving model (epoch =  816, loss = 0.9678)\n",
      "Saving model (epoch =  817, loss = 0.9677)\n",
      "Saving model (epoch =  824, loss = 0.9672)\n",
      "Saving model (epoch =  832, loss = 0.9671)\n",
      "Saving model (epoch =  842, loss = 0.9670)\n",
      "Saving model (epoch =  845, loss = 0.9667)\n",
      "Saving model (epoch =  846, loss = 0.9667)\n",
      "Saving model (epoch =  847, loss = 0.9664)\n",
      "Saving model (epoch =  861, loss = 0.9660)\n",
      "Saving model (epoch =  867, loss = 0.9659)\n",
      "Saving model (epoch =  876, loss = 0.9656)\n",
      "Saving model (epoch =  877, loss = 0.9655)\n",
      "Saving model (epoch =  894, loss = 0.9655)\n",
      "Saving model (epoch =  895, loss = 0.9654)\n",
      "Saving model (epoch =  900, loss = 0.9652)\n",
      "Saving model (epoch =  907, loss = 0.9652)\n",
      "Saving model (epoch =  911, loss = 0.9651)\n",
      "Saving model (epoch =  914, loss = 0.9651)\n",
      "Saving model (epoch =  915, loss = 0.9649)\n",
      "Saving model (epoch =  917, loss = 0.9649)\n",
      "Saving model (epoch =  918, loss = 0.9647)\n",
      "Saving model (epoch =  919, loss = 0.9645)\n",
      "Saving model (epoch =  930, loss = 0.9643)\n",
      "Saving model (epoch =  931, loss = 0.9639)\n",
      "Saving model (epoch =  934, loss = 0.9639)\n",
      "Saving model (epoch =  949, loss = 0.9635)\n",
      "Saving model (epoch =  981, loss = 0.9630)\n",
      "Saving model (epoch =  990, loss = 0.9630)\n",
      "Saving model (epoch =  991, loss = 0.9622)\n",
      "Saving model (epoch = 1029, loss = 0.9621)\n",
      "Saving model (epoch = 1034, loss = 0.9621)\n",
      "Saving model (epoch = 1042, loss = 0.9613)\n",
      "Saving model (epoch = 1066, loss = 0.9612)\n",
      "Saving model (epoch = 1104, loss = 0.9606)\n",
      "Saving model (epoch = 1154, loss = 0.9604)\n",
      "Saving model (epoch = 1155, loss = 0.9604)\n",
      "Saving model (epoch = 1226, loss = 0.9604)\n",
      "Saving model (epoch = 1230, loss = 0.9601)\n",
      "Saving model (epoch = 1253, loss = 0.9598)\n",
      "Saving model (epoch = 1288, loss = 0.9595)\n",
      "Saving model (epoch = 1298, loss = 0.9595)\n",
      "Saving model (epoch = 1332, loss = 0.9594)\n",
      "Saving model (epoch = 1354, loss = 0.9592)\n",
      "Saving model (epoch = 1368, loss = 0.9589)\n",
      "Saving model (epoch = 1528, loss = 0.9589)\n",
      "Saving model (epoch = 1570, loss = 0.9588)\n",
      "Saving model (epoch = 1577, loss = 0.9582)\n",
      "Finished training after 1778 epochs\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [298.7401123046875,\n",
       "  313.65594482421875,\n",
       "  331.9718017578125,\n",
       "  296.6587829589844,\n",
       "  331.8175048828125,\n",
       "  301.6987609863281,\n",
       "  361.00213623046875,\n",
       "  335.5228271484375,\n",
       "  327.40478515625,\n",
       "  332.2508544921875,\n",
       "  309.3766784667969,\n",
       "  302.6080322265625,\n",
       "  315.30743408203125,\n",
       "  287.9600830078125,\n",
       "  308.6982421875,\n",
       "  284.63006591796875,\n",
       "  317.6744384765625,\n",
       "  338.86090087890625,\n",
       "  331.63043212890625,\n",
       "  333.16925048828125,\n",
       "  277.15142822265625,\n",
       "  318.0115966796875,\n",
       "  298.0248107910156,\n",
       "  286.0996398925781,\n",
       "  314.5250244140625,\n",
       "  306.6583557128906,\n",
       "  287.2508239746094,\n",
       "  288.835205078125,\n",
       "  286.0835266113281,\n",
       "  311.1180725097656,\n",
       "  285.43585205078125,\n",
       "  276.1156311035156,\n",
       "  310.6752014160156,\n",
       "  278.45159912109375,\n",
       "  260.55633544921875,\n",
       "  271.43548583984375,\n",
       "  286.0492858886719,\n",
       "  285.65142822265625,\n",
       "  249.18170166015625,\n",
       "  264.4704284667969,\n",
       "  270.35693359375,\n",
       "  281.57208251953125,\n",
       "  262.0892333984375,\n",
       "  227.35906982421875,\n",
       "  241.6984405517578,\n",
       "  238.87185668945312,\n",
       "  231.49093627929688,\n",
       "  261.9256591796875,\n",
       "  252.175048828125,\n",
       "  240.2585906982422,\n",
       "  210.94667053222656,\n",
       "  228.98486328125,\n",
       "  232.21771240234375,\n",
       "  224.8468017578125,\n",
       "  230.88845825195312,\n",
       "  213.79930114746094,\n",
       "  212.761474609375,\n",
       "  220.87960815429688,\n",
       "  202.20321655273438,\n",
       "  175.50001525878906,\n",
       "  196.90963745117188,\n",
       "  186.62147521972656,\n",
       "  189.6411590576172,\n",
       "  173.15542602539062,\n",
       "  166.17877197265625,\n",
       "  174.44119262695312,\n",
       "  155.99581909179688,\n",
       "  159.2718963623047,\n",
       "  148.76483154296875,\n",
       "  160.1609649658203,\n",
       "  130.56906127929688,\n",
       "  134.66925048828125,\n",
       "  131.6602783203125,\n",
       "  129.06057739257812,\n",
       "  115.80879974365234,\n",
       "  113.28351593017578,\n",
       "  116.85781860351562,\n",
       "  109.29214477539062,\n",
       "  96.21064758300781,\n",
       "  100.44898986816406,\n",
       "  88.33097076416016,\n",
       "  82.69580841064453,\n",
       "  75.30027770996094,\n",
       "  72.62374877929688,\n",
       "  74.25209045410156,\n",
       "  64.81658935546875,\n",
       "  62.53705978393555,\n",
       "  54.7838249206543,\n",
       "  56.14317321777344,\n",
       "  48.91213607788086,\n",
       "  44.12290954589844,\n",
       "  40.05806350708008,\n",
       "  40.9403076171875,\n",
       "  39.62464141845703,\n",
       "  36.25090408325195,\n",
       "  31.548904418945312,\n",
       "  29.117511749267578,\n",
       "  26.898462295532227,\n",
       "  25.090456008911133,\n",
       "  26.15707778930664,\n",
       "  21.033002853393555,\n",
       "  21.657758712768555,\n",
       "  19.607112884521484,\n",
       "  19.926559448242188,\n",
       "  18.266075134277344,\n",
       "  18.455820083618164,\n",
       "  14.948087692260742,\n",
       "  16.89423370361328,\n",
       "  16.125171661376953,\n",
       "  17.677759170532227,\n",
       "  14.24035358428955,\n",
       "  13.376697540283203,\n",
       "  14.125267028808594,\n",
       "  13.889939308166504,\n",
       "  13.636035919189453,\n",
       "  12.40770149230957,\n",
       "  13.328550338745117,\n",
       "  12.195996284484863,\n",
       "  11.642704010009766,\n",
       "  12.573418617248535,\n",
       "  12.05191421508789,\n",
       "  9.623960494995117,\n",
       "  10.363105773925781,\n",
       "  10.630077362060547,\n",
       "  9.809476852416992,\n",
       "  9.894828796386719,\n",
       "  8.927627563476562,\n",
       "  9.252079010009766,\n",
       "  8.769906044006348,\n",
       "  8.042030334472656,\n",
       "  8.922698974609375,\n",
       "  6.2733845710754395,\n",
       "  8.370712280273438,\n",
       "  6.341977596282959,\n",
       "  7.214362144470215,\n",
       "  6.557863235473633,\n",
       "  5.970635890960693,\n",
       "  5.378065586090088,\n",
       "  6.17603063583374,\n",
       "  5.666430473327637,\n",
       "  5.523345470428467,\n",
       "  5.463726997375488,\n",
       "  4.613321781158447,\n",
       "  4.427054405212402,\n",
       "  5.164614200592041,\n",
       "  3.977632522583008,\n",
       "  4.594751358032227,\n",
       "  3.9042000770568848,\n",
       "  3.7403624057769775,\n",
       "  3.6930501461029053,\n",
       "  3.776871681213379,\n",
       "  3.2167043685913086,\n",
       "  3.2168662548065186,\n",
       "  3.7696592807769775,\n",
       "  2.870269298553467,\n",
       "  3.338595151901245,\n",
       "  2.7135097980499268,\n",
       "  3.0765938758850098,\n",
       "  2.797701358795166,\n",
       "  3.251019239425659,\n",
       "  2.6462085247039795,\n",
       "  2.618791103363037,\n",
       "  2.9452877044677734,\n",
       "  2.529792547225952,\n",
       "  2.8277390003204346,\n",
       "  2.503591775894165,\n",
       "  2.035698413848877,\n",
       "  2.0039896965026855,\n",
       "  2.4047155380249023,\n",
       "  2.40008544921875,\n",
       "  1.9442023038864136,\n",
       "  1.9113141298294067,\n",
       "  2.085494041442871,\n",
       "  1.996667742729187,\n",
       "  2.0538618564605713,\n",
       "  2.232539176940918,\n",
       "  2.434272289276123,\n",
       "  2.179424285888672,\n",
       "  2.3774707317352295,\n",
       "  2.0403172969818115,\n",
       "  1.8462382555007935,\n",
       "  2.206935405731201,\n",
       "  2.0933539867401123,\n",
       "  1.9490631818771362,\n",
       "  2.4370853900909424,\n",
       "  1.929651141166687,\n",
       "  1.80328369140625,\n",
       "  1.8523640632629395,\n",
       "  1.8739054203033447,\n",
       "  1.6531075239181519,\n",
       "  1.733097791671753,\n",
       "  1.8904653787612915,\n",
       "  1.695776343345642,\n",
       "  1.75809907913208,\n",
       "  2.1747169494628906,\n",
       "  2.0106987953186035,\n",
       "  2.2934162616729736,\n",
       "  1.8807344436645508,\n",
       "  1.5463156700134277,\n",
       "  2.052251100540161,\n",
       "  1.8532602787017822,\n",
       "  2.082523822784424,\n",
       "  1.5791325569152832,\n",
       "  1.9324101209640503,\n",
       "  1.7308177947998047,\n",
       "  1.8038088083267212,\n",
       "  1.973418951034546,\n",
       "  1.991644263267517,\n",
       "  1.8456106185913086,\n",
       "  1.8280351161956787,\n",
       "  1.901679515838623,\n",
       "  1.8705235719680786,\n",
       "  1.4432474374771118,\n",
       "  1.8932217359542847,\n",
       "  2.0089058876037598,\n",
       "  1.9951437711715698,\n",
       "  1.9129444360733032,\n",
       "  1.8569748401641846,\n",
       "  1.620758295059204,\n",
       "  1.8491463661193848,\n",
       "  1.8570903539657593,\n",
       "  1.8025932312011719,\n",
       "  1.62955641746521,\n",
       "  1.6191939115524292,\n",
       "  1.6051045656204224,\n",
       "  1.6179157495498657,\n",
       "  1.866266131401062,\n",
       "  2.1545400619506836,\n",
       "  2.1175904273986816,\n",
       "  1.8380974531173706,\n",
       "  1.7199674844741821,\n",
       "  1.8529616594314575,\n",
       "  1.6947457790374756,\n",
       "  1.9998481273651123,\n",
       "  1.7605586051940918,\n",
       "  1.7517014741897583,\n",
       "  1.6096848249435425,\n",
       "  1.8460255861282349,\n",
       "  1.668531060218811,\n",
       "  2.0450079441070557,\n",
       "  1.713801383972168,\n",
       "  1.5325924158096313,\n",
       "  1.8947805166244507,\n",
       "  1.8999260663986206,\n",
       "  1.8039166927337646,\n",
       "  1.6756787300109863,\n",
       "  2.246312141418457,\n",
       "  1.490720272064209,\n",
       "  1.393344759941101,\n",
       "  2.1154723167419434,\n",
       "  1.5179201364517212,\n",
       "  1.9055249691009521,\n",
       "  1.5382388830184937,\n",
       "  1.9290249347686768,\n",
       "  1.8235002756118774,\n",
       "  1.4762296676635742,\n",
       "  1.7868667840957642,\n",
       "  2.0455610752105713,\n",
       "  1.6005373001098633,\n",
       "  1.8865861892700195,\n",
       "  1.9799762964248657,\n",
       "  1.665846824645996,\n",
       "  1.481905460357666,\n",
       "  1.4842339754104614,\n",
       "  1.6503551006317139,\n",
       "  1.3758158683776855,\n",
       "  2.052232265472412,\n",
       "  1.8935396671295166,\n",
       "  1.8661251068115234,\n",
       "  1.8871515989303589,\n",
       "  1.8333195447921753,\n",
       "  1.7864081859588623,\n",
       "  1.652642846107483,\n",
       "  1.5237843990325928,\n",
       "  1.637050747871399,\n",
       "  1.6945258378982544,\n",
       "  1.9734649658203125,\n",
       "  1.5011682510375977,\n",
       "  1.6216562986373901,\n",
       "  1.9717379808425903,\n",
       "  1.4859901666641235,\n",
       "  1.8554069995880127,\n",
       "  2.031399965286255,\n",
       "  1.6811110973358154,\n",
       "  1.967582106590271,\n",
       "  1.5156384706497192,\n",
       "  1.5477874279022217,\n",
       "  1.5027886629104614,\n",
       "  1.8743679523468018,\n",
       "  1.4212431907653809,\n",
       "  1.8744399547576904,\n",
       "  1.3477768898010254,\n",
       "  1.8616039752960205,\n",
       "  1.6819422245025635,\n",
       "  1.709472417831421,\n",
       "  1.518512487411499,\n",
       "  1.8722007274627686,\n",
       "  1.79318106174469,\n",
       "  1.6382368803024292,\n",
       "  1.4566758871078491,\n",
       "  2.1758410930633545,\n",
       "  1.3692792654037476,\n",
       "  1.7002480030059814,\n",
       "  1.6385053396224976,\n",
       "  1.8612815141677856,\n",
       "  1.5468188524246216,\n",
       "  1.6568756103515625,\n",
       "  1.5077884197235107,\n",
       "  1.6828058958053589,\n",
       "  1.4778574705123901,\n",
       "  1.5792515277862549,\n",
       "  1.7471352815628052,\n",
       "  1.6638920307159424,\n",
       "  1.6065703630447388,\n",
       "  1.7606902122497559,\n",
       "  1.4139423370361328,\n",
       "  1.548018455505371,\n",
       "  1.9763576984405518,\n",
       "  1.774262547492981,\n",
       "  1.381102204322815,\n",
       "  1.7954405546188354,\n",
       "  1.6100550889968872,\n",
       "  1.5572396516799927,\n",
       "  1.5040441751480103,\n",
       "  1.4472616910934448,\n",
       "  1.7210532426834106,\n",
       "  1.935740351676941,\n",
       "  1.6627891063690186,\n",
       "  1.5335676670074463,\n",
       "  1.6246005296707153,\n",
       "  1.6362413167953491,\n",
       "  1.5960230827331543,\n",
       "  1.7133784294128418,\n",
       "  1.2975863218307495,\n",
       "  1.7351900339126587,\n",
       "  1.964402675628662,\n",
       "  1.7552841901779175,\n",
       "  1.5370913743972778,\n",
       "  1.3805742263793945,\n",
       "  1.6653168201446533,\n",
       "  1.7602314949035645,\n",
       "  1.681653618812561,\n",
       "  1.5307421684265137,\n",
       "  1.668444037437439,\n",
       "  1.5490236282348633,\n",
       "  1.6840946674346924,\n",
       "  1.6351869106292725,\n",
       "  1.5567618608474731,\n",
       "  1.5451345443725586,\n",
       "  1.5120388269424438,\n",
       "  1.4039779901504517,\n",
       "  1.539098858833313,\n",
       "  1.4022350311279297,\n",
       "  1.938215970993042,\n",
       "  1.6622025966644287,\n",
       "  1.8144863843917847,\n",
       "  1.4396933317184448,\n",
       "  1.6412160396575928,\n",
       "  1.6875395774841309,\n",
       "  1.4687070846557617,\n",
       "  1.6755082607269287,\n",
       "  1.7973307371139526,\n",
       "  1.5245156288146973,\n",
       "  1.768040657043457,\n",
       "  1.571181058883667,\n",
       "  1.6640502214431763,\n",
       "  1.2462421655654907,\n",
       "  1.7668598890304565,\n",
       "  1.4438903331756592,\n",
       "  1.4221471548080444,\n",
       "  1.3706401586532593,\n",
       "  1.6136884689331055,\n",
       "  1.9855763912200928,\n",
       "  1.705255389213562,\n",
       "  1.573986530303955,\n",
       "  1.4962576627731323,\n",
       "  1.5490427017211914,\n",
       "  1.6849777698516846,\n",
       "  1.3539913892745972,\n",
       "  1.4601010084152222,\n",
       "  1.5369762182235718,\n",
       "  1.7489521503448486,\n",
       "  1.4972871541976929,\n",
       "  1.8360791206359863,\n",
       "  1.4957643747329712,\n",
       "  1.437059760093689,\n",
       "  2.0144479274749756,\n",
       "  1.386285662651062,\n",
       "  1.3520731925964355,\n",
       "  1.3628283739089966,\n",
       "  1.4758245944976807,\n",
       "  1.844246506690979,\n",
       "  1.2298327684402466,\n",
       "  1.6334596872329712,\n",
       "  1.8315491676330566,\n",
       "  1.4740313291549683,\n",
       "  1.390966773033142,\n",
       "  1.4454759359359741,\n",
       "  1.7921020984649658,\n",
       "  1.4940904378890991,\n",
       "  1.5218355655670166,\n",
       "  1.3323137760162354,\n",
       "  1.6005891561508179,\n",
       "  1.2810572385787964,\n",
       "  1.1215163469314575,\n",
       "  1.9924354553222656,\n",
       "  1.8711477518081665,\n",
       "  1.9916595220565796,\n",
       "  1.3585329055786133,\n",
       "  1.440153956413269,\n",
       "  1.5285886526107788,\n",
       "  1.5174479484558105,\n",
       "  1.3442796468734741,\n",
       "  1.5820958614349365,\n",
       "  1.3243428468704224,\n",
       "  1.9228944778442383,\n",
       "  1.4912360906600952,\n",
       "  1.7946441173553467,\n",
       "  1.5462251901626587,\n",
       "  1.353646993637085,\n",
       "  1.6745738983154297,\n",
       "  1.4287654161453247,\n",
       "  1.5263806581497192,\n",
       "  1.7809253931045532,\n",
       "  1.3407343626022339,\n",
       "  1.420005202293396,\n",
       "  1.540216088294983,\n",
       "  1.5520702600479126,\n",
       "  1.6294821500778198,\n",
       "  1.4591928720474243,\n",
       "  1.6297197341918945,\n",
       "  1.3187319040298462,\n",
       "  1.5676780939102173,\n",
       "  1.308814525604248,\n",
       "  1.2707102298736572,\n",
       "  1.5335456132888794,\n",
       "  1.7624235153198242,\n",
       "  1.7938218116760254,\n",
       "  1.6159254312515259,\n",
       "  1.4767102003097534,\n",
       "  1.1509584188461304,\n",
       "  1.442949652671814,\n",
       "  1.319145679473877,\n",
       "  1.454539179801941,\n",
       "  1.3615193367004395,\n",
       "  1.8885053396224976,\n",
       "  1.7452927827835083,\n",
       "  1.6306788921356201,\n",
       "  1.6399117708206177,\n",
       "  1.606071949005127,\n",
       "  1.275209665298462,\n",
       "  2.00028395652771,\n",
       "  1.4691150188446045,\n",
       "  1.514944314956665,\n",
       "  1.711086630821228,\n",
       "  1.0760834217071533,\n",
       "  1.5962647199630737,\n",
       "  1.514209270477295,\n",
       "  1.4649884700775146,\n",
       "  1.5191915035247803,\n",
       "  1.5522745847702026,\n",
       "  1.3305692672729492,\n",
       "  1.3199511766433716,\n",
       "  1.4961395263671875,\n",
       "  1.3723725080490112,\n",
       "  1.830923318862915,\n",
       "  1.4225887060165405,\n",
       "  1.5612138509750366,\n",
       "  1.6504218578338623,\n",
       "  1.5425560474395752,\n",
       "  1.4628232717514038,\n",
       "  1.0171390771865845,\n",
       "  1.542238712310791,\n",
       "  1.4903522729873657,\n",
       "  1.610074520111084,\n",
       "  1.7381083965301514,\n",
       "  1.810085654258728,\n",
       "  1.7429194450378418,\n",
       "  1.2365989685058594,\n",
       "  1.2905644178390503,\n",
       "  1.6132493019104004,\n",
       "  1.6095222234725952,\n",
       "  1.3596813678741455,\n",
       "  1.3776042461395264,\n",
       "  1.218369722366333,\n",
       "  1.7433884143829346,\n",
       "  1.4232913255691528,\n",
       "  1.4690495729446411,\n",
       "  1.3766783475875854,\n",
       "  1.834085464477539,\n",
       "  1.5655690431594849,\n",
       "  1.4290363788604736,\n",
       "  1.2126264572143555,\n",
       "  1.8818150758743286,\n",
       "  1.7626264095306396,\n",
       "  1.359307885169983,\n",
       "  1.1954171657562256,\n",
       "  1.6031609773635864,\n",
       "  1.1798608303070068,\n",
       "  1.7526333332061768,\n",
       "  1.3447959423065186,\n",
       "  1.5060926675796509,\n",
       "  1.2597284317016602,\n",
       "  1.3472416400909424,\n",
       "  1.6725859642028809,\n",
       "  1.4452223777770996,\n",
       "  1.4423646926879883,\n",
       "  1.4670058488845825,\n",
       "  1.7371026277542114,\n",
       "  1.6220405101776123,\n",
       "  1.5513676404953003,\n",
       "  1.5418611764907837,\n",
       "  1.3574954271316528,\n",
       "  1.519798994064331,\n",
       "  1.5823432207107544,\n",
       "  1.23372220993042,\n",
       "  1.3023031949996948,\n",
       "  1.4608752727508545,\n",
       "  1.5138179063796997,\n",
       "  1.7584675550460815,\n",
       "  1.356762170791626,\n",
       "  1.6045161485671997,\n",
       "  1.35641610622406,\n",
       "  1.273511528968811,\n",
       "  1.5776299238204956,\n",
       "  1.6435303688049316,\n",
       "  1.4683245420455933,\n",
       "  1.4463142156600952,\n",
       "  1.6566780805587769,\n",
       "  1.233033299446106,\n",
       "  1.4577115774154663,\n",
       "  1.6202213764190674,\n",
       "  1.353021502494812,\n",
       "  1.5089722871780396,\n",
       "  1.4375463724136353,\n",
       "  1.395214557647705,\n",
       "  1.331431269645691,\n",
       "  1.8205007314682007,\n",
       "  1.4489061832427979,\n",
       "  1.172739028930664,\n",
       "  1.6312577724456787,\n",
       "  1.368316411972046,\n",
       "  1.446670651435852,\n",
       "  1.5144621133804321,\n",
       "  1.4149296283721924,\n",
       "  1.6774390935897827,\n",
       "  1.065851092338562,\n",
       "  1.4671344757080078,\n",
       "  1.55557382106781,\n",
       "  1.4176114797592163,\n",
       "  1.6807016134262085,\n",
       "  1.5187633037567139,\n",
       "  1.27937650680542,\n",
       "  1.5677188634872437,\n",
       "  1.4381895065307617,\n",
       "  1.3664941787719727,\n",
       "  1.4865610599517822,\n",
       "  1.3525103330612183,\n",
       "  1.4275007247924805,\n",
       "  1.3778719902038574,\n",
       "  1.7114485502243042,\n",
       "  1.5328749418258667,\n",
       "  1.3042829036712646,\n",
       "  1.4848926067352295,\n",
       "  1.315845012664795,\n",
       "  1.4688324928283691,\n",
       "  1.4995325803756714,\n",
       "  1.4354358911514282,\n",
       "  1.2599763870239258,\n",
       "  1.4508562088012695,\n",
       "  1.7749019861221313,\n",
       "  1.53092622756958,\n",
       "  1.39296555519104,\n",
       "  1.1625077724456787,\n",
       "  1.5654693841934204,\n",
       "  1.286839246749878,\n",
       "  1.2062621116638184,\n",
       "  1.5309979915618896,\n",
       "  1.4547746181488037,\n",
       "  1.5292434692382812,\n",
       "  1.5234649181365967,\n",
       "  1.554117202758789,\n",
       "  1.2067700624465942,\n",
       "  1.2732244729995728,\n",
       "  1.7676503658294678,\n",
       "  1.306823492050171,\n",
       "  1.6250380277633667,\n",
       "  1.3648595809936523,\n",
       "  1.2147799730300903,\n",
       "  1.5644142627716064,\n",
       "  1.3764817714691162,\n",
       "  1.3515688180923462,\n",
       "  1.4116092920303345,\n",
       "  1.343553900718689,\n",
       "  1.706274151802063,\n",
       "  1.5073350667953491,\n",
       "  1.4477266073226929,\n",
       "  1.4554715156555176,\n",
       "  1.3401447534561157,\n",
       "  1.3506526947021484,\n",
       "  1.631667137145996,\n",
       "  1.4042555093765259,\n",
       "  1.5323013067245483,\n",
       "  1.3117984533309937,\n",
       "  1.3257654905319214,\n",
       "  1.274179220199585,\n",
       "  1.3433586359024048,\n",
       "  1.3830097913742065,\n",
       "  1.6104645729064941,\n",
       "  1.458243489265442,\n",
       "  1.19112229347229,\n",
       "  1.6307934522628784,\n",
       "  1.4531166553497314,\n",
       "  1.3914949893951416,\n",
       "  1.2823697328567505,\n",
       "  1.1934808492660522,\n",
       "  1.4749300479888916,\n",
       "  1.5821422338485718,\n",
       "  1.5042941570281982,\n",
       "  1.5536612272262573,\n",
       "  1.569395899772644,\n",
       "  1.6834412813186646,\n",
       "  1.2593579292297363,\n",
       "  1.230987310409546,\n",
       "  1.3509447574615479,\n",
       "  1.4797241687774658,\n",
       "  1.352830410003662,\n",
       "  1.6220492124557495,\n",
       "  1.5716952085494995,\n",
       "  0.9155448079109192,\n",
       "  1.3544429540634155,\n",
       "  1.478627324104309,\n",
       "  1.2313302755355835,\n",
       "  1.239561915397644,\n",
       "  1.2525230646133423,\n",
       "  1.5707234144210815,\n",
       "  1.413451075553894,\n",
       "  1.2688639163970947,\n",
       "  1.6597678661346436,\n",
       "  1.7572991847991943,\n",
       "  1.3815388679504395,\n",
       "  1.404191255569458,\n",
       "  1.2381395101547241,\n",
       "  1.4135262966156006,\n",
       "  1.1939783096313477,\n",
       "  1.6939129829406738,\n",
       "  1.2849010229110718,\n",
       "  1.646217703819275,\n",
       "  1.253470778465271,\n",
       "  1.6488077640533447,\n",
       "  1.371097445487976,\n",
       "  1.3626817464828491,\n",
       "  1.4509550333023071,\n",
       "  1.3672701120376587,\n",
       "  1.542662262916565,\n",
       "  1.2692288160324097,\n",
       "  1.2640098333358765,\n",
       "  1.589748501777649,\n",
       "  1.3038523197174072,\n",
       "  1.572854995727539,\n",
       "  1.5936110019683838,\n",
       "  1.433801293373108,\n",
       "  1.45890212059021,\n",
       "  1.2948907613754272,\n",
       "  1.3167412281036377,\n",
       "  1.2115976810455322,\n",
       "  1.346634030342102,\n",
       "  1.6065397262573242,\n",
       "  1.2833530902862549,\n",
       "  1.4863072633743286,\n",
       "  1.461148738861084,\n",
       "  1.6259815692901611,\n",
       "  1.3988860845565796,\n",
       "  1.1435805559158325,\n",
       "  1.4354265928268433,\n",
       "  1.5523920059204102,\n",
       "  1.2746769189834595,\n",
       "  1.2046951055526733,\n",
       "  1.5994486808776855,\n",
       "  1.2201420068740845,\n",
       "  1.2463276386260986,\n",
       "  1.1965471506118774,\n",
       "  1.3714951276779175,\n",
       "  1.1562447547912598,\n",
       "  1.2370007038116455,\n",
       "  1.8605560064315796,\n",
       "  1.5079325437545776,\n",
       "  1.278925895690918,\n",
       "  1.679084300994873,\n",
       "  1.3932907581329346,\n",
       "  1.413820743560791,\n",
       "  1.6864420175552368,\n",
       "  1.2859944105148315,\n",
       "  1.4295645952224731,\n",
       "  1.273457407951355,\n",
       "  1.267784833908081,\n",
       "  1.4151113033294678,\n",
       "  1.5796273946762085,\n",
       "  1.2377328872680664,\n",
       "  1.2661641836166382,\n",
       "  1.2525663375854492,\n",
       "  1.5207297801971436,\n",
       "  1.0939490795135498,\n",
       "  1.3072330951690674,\n",
       "  1.4911588430404663,\n",
       "  1.6061350107192993,\n",
       "  1.3399220705032349,\n",
       "  1.4545106887817383,\n",
       "  1.3111659288406372,\n",
       "  1.510785460472107,\n",
       "  1.3354123830795288,\n",
       "  1.4826076030731201,\n",
       "  1.301700472831726,\n",
       "  1.3588505983352661,\n",
       "  1.3976633548736572,\n",
       "  1.2651363611221313,\n",
       "  1.2979189157485962,\n",
       "  1.2275874614715576,\n",
       "  1.731087327003479,\n",
       "  1.4314429759979248,\n",
       "  1.2789546251296997,\n",
       "  1.4267700910568237,\n",
       "  1.5305014848709106,\n",
       "  1.2996571063995361,\n",
       "  1.6715141534805298,\n",
       "  1.4221163988113403,\n",
       "  1.2103818655014038,\n",
       "  1.3066520690917969,\n",
       "  1.4032740592956543,\n",
       "  1.1723483800888062,\n",
       "  1.5349221229553223,\n",
       "  1.473807454109192,\n",
       "  1.28425931930542,\n",
       "  1.1800570487976074,\n",
       "  1.5819447040557861,\n",
       "  1.1841775178909302,\n",
       "  1.2269983291625977,\n",
       "  1.203188419342041,\n",
       "  1.492944359779358,\n",
       "  1.6629822254180908,\n",
       "  1.1402642726898193,\n",
       "  1.4899762868881226,\n",
       "  1.4471211433410645,\n",
       "  1.489867925643921,\n",
       "  1.6114954948425293,\n",
       "  1.2531993389129639,\n",
       "  1.2171449661254883,\n",
       "  1.5664548873901367,\n",
       "  1.2358312606811523,\n",
       "  1.2155812978744507,\n",
       "  1.0815815925598145,\n",
       "  1.7059074640274048,\n",
       "  1.3778605461120605,\n",
       "  1.564629077911377,\n",
       "  1.2641470432281494,\n",
       "  1.3480907678604126,\n",
       "  1.4238526821136475,\n",
       "  1.2741214036941528,\n",
       "  1.178971529006958,\n",
       "  1.4901520013809204,\n",
       "  1.4662511348724365,\n",
       "  1.2678693532943726,\n",
       "  1.693160891532898,\n",
       "  1.277078628540039,\n",
       "  1.454990029335022,\n",
       "  1.2060397863388062,\n",
       "  1.253467082977295,\n",
       "  1.3223167657852173,\n",
       "  1.3146252632141113,\n",
       "  1.3999197483062744,\n",
       "  1.3588502407073975,\n",
       "  0.973200261592865,\n",
       "  1.4224625825881958,\n",
       "  1.1278798580169678,\n",
       "  1.682716965675354,\n",
       "  1.3391003608703613,\n",
       "  1.2261946201324463,\n",
       "  1.5749595165252686,\n",
       "  1.5198335647583008,\n",
       "  1.3943274021148682,\n",
       "  1.3691375255584717,\n",
       "  1.460214376449585,\n",
       "  1.3960522413253784,\n",
       "  1.4364006519317627,\n",
       "  1.2282977104187012,\n",
       "  1.4479275941848755,\n",
       "  1.4667232036590576,\n",
       "  1.449960470199585,\n",
       "  1.2216672897338867,\n",
       "  1.0046237707138062,\n",
       "  1.0141903162002563,\n",
       "  1.2490534782409668,\n",
       "  1.4584308862686157,\n",
       "  1.2073842287063599,\n",
       "  1.5291962623596191,\n",
       "  1.3578588962554932,\n",
       "  1.6078826189041138,\n",
       "  1.2283419370651245,\n",
       "  1.422109603881836,\n",
       "  1.518643856048584,\n",
       "  1.2106907367706299,\n",
       "  1.5025224685668945,\n",
       "  1.4206067323684692,\n",
       "  1.4919010400772095,\n",
       "  1.114632487297058,\n",
       "  1.2722622156143188,\n",
       "  1.2375378608703613,\n",
       "  1.4382892847061157,\n",
       "  1.4113187789916992,\n",
       "  1.4451117515563965,\n",
       "  1.0781445503234863,\n",
       "  1.3616478443145752,\n",
       "  1.3590173721313477,\n",
       "  1.2962491512298584,\n",
       "  1.8346306085586548,\n",
       "  1.126936435699463,\n",
       "  1.3739839792251587,\n",
       "  1.5262008905410767,\n",
       "  1.0948154926300049,\n",
       "  1.4683287143707275,\n",
       "  1.619600534439087,\n",
       "  1.3752034902572632,\n",
       "  1.3244467973709106,\n",
       "  1.2937685251235962,\n",
       "  1.3859695196151733,\n",
       "  1.3665131330490112,\n",
       "  1.1241674423217773,\n",
       "  1.362007737159729,\n",
       "  1.3302524089813232,\n",
       "  1.250340461730957,\n",
       "  1.198874592781067,\n",
       "  1.2014963626861572,\n",
       "  1.553848385810852,\n",
       "  1.4289228916168213,\n",
       "  1.2486963272094727,\n",
       "  1.3731211423873901,\n",
       "  1.369262456893921,\n",
       "  1.3384184837341309,\n",
       "  1.3160390853881836,\n",
       "  1.4215840101242065,\n",
       "  1.202683925628662,\n",
       "  1.5454840660095215,\n",
       "  1.1809324026107788,\n",
       "  1.741843342781067,\n",
       "  1.1439423561096191,\n",
       "  1.0356496572494507,\n",
       "  1.4651671648025513,\n",
       "  1.329135537147522,\n",
       "  1.4003640413284302,\n",
       "  1.3691937923431396,\n",
       "  1.4184701442718506,\n",
       "  1.4670425653457642,\n",
       "  1.2698380947113037,\n",
       "  1.4853215217590332,\n",
       "  1.4313080310821533,\n",
       "  1.254332423210144,\n",
       "  1.3912057876586914,\n",
       "  1.1643469333648682,\n",
       "  1.2160054445266724,\n",
       "  1.2529081106185913,\n",
       "  1.2756379842758179,\n",
       "  1.4019564390182495,\n",
       "  1.2349276542663574,\n",
       "  1.3652468919754028,\n",
       "  1.3886713981628418,\n",
       "  1.4427459239959717,\n",
       "  1.055260419845581,\n",
       "  1.614180326461792,\n",
       "  1.2742642164230347,\n",
       "  1.2752445936203003,\n",
       "  1.4467964172363281,\n",
       "  1.5149916410446167,\n",
       "  1.2550048828125,\n",
       "  1.1295278072357178,\n",
       "  1.3992915153503418,\n",
       "  1.592105746269226,\n",
       "  1.1104108095169067,\n",
       "  1.3991405963897705,\n",
       "  1.440253734588623,\n",
       "  0.9273641109466553,\n",
       "  1.2482143640518188,\n",
       "  1.4904342889785767,\n",
       "  1.2695207595825195,\n",
       "  1.4993833303451538,\n",
       "  1.2415330410003662,\n",
       "  1.360036849975586,\n",
       "  1.2638695240020752,\n",
       "  1.2143561840057373,\n",
       "  1.2383739948272705,\n",
       "  1.5318642854690552,\n",
       "  1.4554674625396729,\n",
       "  1.3507649898529053,\n",
       "  1.6509257555007935,\n",
       "  1.1225852966308594,\n",
       "  1.324861764907837,\n",
       "  1.1361005306243896,\n",
       "  1.0789927244186401,\n",
       "  1.332183599472046,\n",
       "  1.3854073286056519,\n",
       "  1.4704420566558838,\n",
       "  1.510048747062683,\n",
       "  1.48362135887146,\n",
       "  1.2905068397521973,\n",
       "  1.1527851819992065,\n",
       "  1.0873507261276245,\n",
       "  1.451474666595459,\n",
       "  1.4208388328552246,\n",
       "  1.3312753438949585,\n",
       "  1.3660106658935547,\n",
       "  1.077252984046936,\n",
       "  1.1635220050811768,\n",
       "  1.017457127571106,\n",
       "  1.697524070739746,\n",
       "  1.3061206340789795,\n",
       "  1.2986117601394653,\n",
       "  1.0334492921829224,\n",
       "  1.355177402496338,\n",
       "  1.3959628343582153,\n",
       "  1.5586825609207153,\n",
       "  1.4132955074310303,\n",
       "  1.2329504489898682,\n",
       "  1.3220158815383911,\n",
       "  1.319108486175537,\n",
       "  1.262170672416687,\n",
       "  1.1226189136505127,\n",
       "  1.6870046854019165,\n",
       "  1.5124484300613403,\n",
       "  1.309114694595337,\n",
       "  1.197486400604248,\n",
       "  1.1877650022506714,\n",
       "  1.347732424736023,\n",
       "  1.41181480884552,\n",
       "  1.185268759727478,\n",
       "  1.2804065942764282,\n",
       "  1.3427674770355225,\n",
       "  1.1575582027435303,\n",
       "  1.2765772342681885,\n",
       "  1.4092316627502441,\n",
       "  1.489111304283142,\n",
       "  1.2487858533859253,\n",
       "  1.3254157304763794,\n",
       "  1.5019210577011108,\n",
       "  1.5047141313552856,\n",
       "  0.938998281955719,\n",
       "  1.5163739919662476,\n",
       "  1.471788763999939,\n",
       "  1.1179769039154053,\n",
       "  1.2685675621032715,\n",
       "  1.2412538528442383,\n",
       "  1.2291896343231201,\n",
       "  1.6154253482818604,\n",
       "  1.4424384832382202,\n",
       "  1.0957379341125488,\n",
       "  1.4498322010040283,\n",
       "  1.2218149900436401,\n",
       "  1.373219609260559,\n",
       "  1.1091632843017578,\n",
       "  1.2525161504745483,\n",
       "  1.4416234493255615,\n",
       "  1.0415449142456055,\n",
       "  1.3133440017700195,\n",
       "  1.3881083726882935,\n",
       "  1.0755819082260132,\n",
       "  1.6525923013687134,\n",
       "  1.1687047481536865,\n",
       "  1.11079740524292,\n",
       "  1.1327046155929565,\n",
       "  1.484592080116272,\n",
       "  1.46726655960083,\n",
       "  1.2981839179992676,\n",
       "  1.320509433746338,\n",
       "  1.4178943634033203,\n",
       "  1.1036251783370972,\n",
       "  1.3943605422973633,\n",
       "  1.018052339553833,\n",
       "  1.2926079034805298,\n",
       "  1.511098861694336,\n",
       "  1.1648194789886475,\n",
       "  1.4651238918304443,\n",
       "  1.4162805080413818,\n",
       "  1.47503662109375,\n",
       "  1.1906440258026123,\n",
       "  1.5993292331695557,\n",
       "  1.1678550243377686,\n",
       "  1.1901620626449585,\n",
       "  1.0526572465896606,\n",
       "  1.0416024923324585,\n",
       "  1.5914206504821777,\n",
       "  1.2527955770492554,\n",
       "  1.557463526725769,\n",
       "  1.3191889524459839,\n",
       "  1.1631355285644531,\n",
       "  1.4631984233856201,\n",
       "  1.0826399326324463,\n",
       "  1.6034044027328491,\n",
       "  1.3004474639892578,\n",
       "  1.4076690673828125,\n",
       "  1.2770496606826782,\n",
       "  1.1144590377807617,\n",
       "  1.2929350137710571,\n",
       "  ...],\n",
       " 'dev': [316.91558724862557,\n",
       "  303.3373865198206,\n",
       "  285.55394490559894,\n",
       "  262.619212962963,\n",
       "  232.2632440637659,\n",
       "  191.76038671422887,\n",
       "  141.3372977927879,\n",
       "  88.11663168447988,\n",
       "  44.74523586697049,\n",
       "  21.45589651884856,\n",
       "  13.566224098205566,\n",
       "  10.176230042069047,\n",
       "  7.114469987374765,\n",
       "  4.7068731873123735,\n",
       "  3.2239891069906728,\n",
       "  2.4217613803015814,\n",
       "  2.0267513681341103,\n",
       "  1.865627302063836,\n",
       "  1.805246180958218,\n",
       "  1.7813750328841034,\n",
       "  1.7631115780936346,\n",
       "  1.744204216533237,\n",
       "  1.7230544752544827,\n",
       "  1.702512467349017,\n",
       "  1.6829791907910947,\n",
       "  1.6642944106349238,\n",
       "  1.646294704190007,\n",
       "  1.6303393796638206,\n",
       "  1.615365191742226,\n",
       "  1.6013115909364488,\n",
       "  1.5877391894658406,\n",
       "  1.5731759027198509,\n",
       "  1.5618395143085055,\n",
       "  1.5489438860504716,\n",
       "  1.5375134194338764,\n",
       "  1.5267618276454784,\n",
       "  1.51721520335586,\n",
       "  1.5067792865965102,\n",
       "  1.4970834255218506,\n",
       "  1.4886101881663005,\n",
       "  1.479855188617,\n",
       "  1.470942704765885,\n",
       "  1.462726769623933,\n",
       "  1.454655201346786,\n",
       "  1.4472963589209098,\n",
       "  1.4398626883824666,\n",
       "  1.4321322882616963,\n",
       "  1.425904463838648,\n",
       "  1.4201029671563044,\n",
       "  1.4132773125613178,\n",
       "  1.407184949627629,\n",
       "  1.4020925142146923,\n",
       "  1.3963235086864896,\n",
       "  1.390441029160111,\n",
       "  1.3849788286067821,\n",
       "  1.380633446905348,\n",
       "  1.3750757817868833,\n",
       "  1.369537940731755,\n",
       "  1.364419455881472,\n",
       "  1.3595808700278953,\n",
       "  1.3549982795008906,\n",
       "  1.350503475577743,\n",
       "  1.346988664733039,\n",
       "  1.3426294944904469,\n",
       "  1.337719687709102,\n",
       "  1.3344202792202984,\n",
       "  1.3305949281763148,\n",
       "  1.3269626785207678,\n",
       "  1.3223608864678278,\n",
       "  1.3195700954507898,\n",
       "  1.3159472854049117,\n",
       "  1.3123860535798249,\n",
       "  1.3094983321649056,\n",
       "  1.305577238400777,\n",
       "  1.3021446510597512,\n",
       "  1.2992664222364072,\n",
       "  1.2966097725762262,\n",
       "  1.2932725968184295,\n",
       "  1.29016880635862,\n",
       "  1.2874735682098954,\n",
       "  1.2842315214651603,\n",
       "  1.2813189736119024,\n",
       "  1.2792551120122273,\n",
       "  1.2761957557113082,\n",
       "  1.2734400475466694,\n",
       "  1.270885569077951,\n",
       "  1.2685301038953993,\n",
       "  1.2656027829205547,\n",
       "  1.262710076791269,\n",
       "  1.2603989353886358,\n",
       "  1.2577967996950503,\n",
       "  1.2556272568526092,\n",
       "  1.2530069395347878,\n",
       "  1.2506341183627094,\n",
       "  1.2488872166033145,\n",
       "  1.2479400943826746,\n",
       "  1.2448807292514377,\n",
       "  1.2420108803996333,\n",
       "  1.2402869507118508,\n",
       "  1.238643103175693,\n",
       "  1.236346584779245,\n",
       "  1.2345150620849044,\n",
       "  1.2322834862603083,\n",
       "  1.230633603201972,\n",
       "  1.2288996864248205,\n",
       "  1.2272184027565851,\n",
       "  1.2252929519723963,\n",
       "  1.2235178726690787,\n",
       "  1.221076250076294,\n",
       "  1.2200499066600092,\n",
       "  1.2184847195943196,\n",
       "  1.216979459480003,\n",
       "  1.215244425667657,\n",
       "  1.2131433266180534,\n",
       "  1.2123011924602367,\n",
       "  1.2108081799966317,\n",
       "  1.2093689574135675,\n",
       "  1.20732910544784,\n",
       "  1.2056430048412747,\n",
       "  1.2044142396361739,\n",
       "  1.2029569193168923,\n",
       "  1.201913798296893,\n",
       "  1.2002648071006492,\n",
       "  1.1990340241679438,\n",
       "  1.1973840792973836,\n",
       "  1.1964260472191706,\n",
       "  1.1945110471160323,\n",
       "  1.1926799791830558,\n",
       "  1.1913183839232833,\n",
       "  1.1903135776519775,\n",
       "  1.1884911987516615,\n",
       "  1.1873149032945987,\n",
       "  1.1859960820939806,\n",
       "  1.184806474932918,\n",
       "  1.1831729809443157,\n",
       "  1.181445011386165,\n",
       "  1.1804218424691095,\n",
       "  1.1796834777902674,\n",
       "  1.1786615097964253,\n",
       "  1.1769978161211367,\n",
       "  1.1763423283894856,\n",
       "  1.1742708727165505,\n",
       "  1.1733763880199857,\n",
       "  1.1721711953481038,\n",
       "  1.1704923709233601,\n",
       "  1.169119914372762,\n",
       "  1.1680774247204815,\n",
       "  1.1674596203698053,\n",
       "  1.1661121050516765,\n",
       "  1.1648133021813851,\n",
       "  1.1634368543271665,\n",
       "  1.1621259186002943,\n",
       "  1.1607288210480302,\n",
       "  1.1603694800977353,\n",
       "  1.1592655402642709,\n",
       "  1.1576681357842904,\n",
       "  1.1561131477355957,\n",
       "  1.1551580561531916,\n",
       "  1.1536942543806854,\n",
       "  1.153091064205876,\n",
       "  1.1518632217689797,\n",
       "  1.1511908019030537,\n",
       "  1.1501484491206981,\n",
       "  1.148642204425953,\n",
       "  1.1476912719232064,\n",
       "  1.146529546490422,\n",
       "  1.1454381898597434,\n",
       "  1.1447653461385656,\n",
       "  1.1437000566058688,\n",
       "  1.1427156351230763,\n",
       "  1.1418315128043846,\n",
       "  1.1406970818837483,\n",
       "  1.13999934108169,\n",
       "  1.1383608888696741,\n",
       "  1.137361137955277,\n",
       "  1.1365201826448794,\n",
       "  1.1358842540670324,\n",
       "  1.1344538397259183,\n",
       "  1.1339519288804796,\n",
       "  1.1327284574508667,\n",
       "  1.1319392787085638,\n",
       "  1.1314464851661965,\n",
       "  1.1305005153020222,\n",
       "  1.129918888763145,\n",
       "  1.1290169689390395,\n",
       "  1.1274415077986542,\n",
       "  1.1274144340444494,\n",
       "  1.1259114344914753,\n",
       "  1.1252437167697482,\n",
       "  1.1244683972111456,\n",
       "  1.123740350758588,\n",
       "  1.1224982385282163,\n",
       "  1.1220791119116325,\n",
       "  1.1211658981111314,\n",
       "  1.119832921911169,\n",
       "  1.1191997042408697,\n",
       "  1.1186600349567555,\n",
       "  1.1178065759164315,\n",
       "  1.1173240564487599,\n",
       "  1.1163500150044758,\n",
       "  1.11576513449351,\n",
       "  1.1143078759864524,\n",
       "  1.1140758328967624,\n",
       "  1.1125246683756511,\n",
       "  1.111800542584172,\n",
       "  1.1110862890879314,\n",
       "  1.1100127608687789,\n",
       "  1.1091487319381148,\n",
       "  1.1088276086030182,\n",
       "  1.1082932772459808,\n",
       "  1.1074324978722467,\n",
       "  1.10652666621738,\n",
       "  1.1051229194358543,\n",
       "  1.1044887436760797,\n",
       "  1.1043705189669575,\n",
       "  1.1038210965968944,\n",
       "  1.1028195707886308,\n",
       "  1.1015875427811235,\n",
       "  1.1007147630055745,\n",
       "  1.099982394112481,\n",
       "  1.0997442536883884,\n",
       "  1.1002845410947446,\n",
       "  1.0989936987559001,\n",
       "  1.098278694682651,\n",
       "  1.0971048363932856,\n",
       "  1.0961741032423797,\n",
       "  1.0963594825179488,\n",
       "  1.095549914571974,\n",
       "  1.0943384214683816,\n",
       "  1.0931821090203744,\n",
       "  1.0931869789406106,\n",
       "  1.0922539234161377,\n",
       "  1.0920220878389146,\n",
       "  1.0911362391931039,\n",
       "  1.090410660814356,\n",
       "  1.0899026526345148,\n",
       "  1.0893333355585735,\n",
       "  1.0893074715578999,\n",
       "  1.0879914186618946,\n",
       "  1.0881140850208424,\n",
       "  1.0874775250752766,\n",
       "  1.0864417729554352,\n",
       "  1.0851550234688654,\n",
       "  1.085153372199447,\n",
       "  1.0843569702572293,\n",
       "  1.0829324015864619,\n",
       "  1.082479437192281,\n",
       "  1.0822405020395915,\n",
       "  1.0827840831544664,\n",
       "  1.081548430301525,\n",
       "  1.0803735741862543,\n",
       "  1.079998426967197,\n",
       "  1.079382132600855,\n",
       "  1.079091986020406,\n",
       "  1.078374637497796,\n",
       "  1.078383414833634,\n",
       "  1.0772927822890106,\n",
       "  1.0767448610729642,\n",
       "  1.075667632950677,\n",
       "  1.0756754124606098,\n",
       "  1.074472842393098,\n",
       "  1.0740483116220545,\n",
       "  1.0739809539582994,\n",
       "  1.0731381398660165,\n",
       "  1.0727194547653198,\n",
       "  1.0721324108265065,\n",
       "  1.071341633796692,\n",
       "  1.0708611408869426,\n",
       "  1.0700312587949965,\n",
       "  1.0700002952858254,\n",
       "  1.0695913941771895,\n",
       "  1.0691727223219696,\n",
       "  1.0679184507440638,\n",
       "  1.067776706483629,\n",
       "  1.0673763796135232,\n",
       "  1.0670822064081829,\n",
       "  1.066595059854013,\n",
       "  1.0663852647498802,\n",
       "  1.0652980539533827,\n",
       "  1.064433256785075,\n",
       "  1.0641303989622328,\n",
       "  1.0639854890328866,\n",
       "  1.063925513514766,\n",
       "  1.062998608306602,\n",
       "  1.0623740752538045,\n",
       "  1.062380384515833,\n",
       "  1.0612409114837646,\n",
       "  1.06094166526088,\n",
       "  1.0603004473227042,\n",
       "  1.059455531614798,\n",
       "  1.0602871356187042,\n",
       "  1.059844418808266,\n",
       "  1.058564473081518,\n",
       "  1.0579060316085815,\n",
       "  1.0570521796191181,\n",
       "  1.0571811729007297,\n",
       "  1.0568766284871984,\n",
       "  1.0563065652494077,\n",
       "  1.0556720936739887,\n",
       "  1.0554043407793399,\n",
       "  1.0544249260867085,\n",
       "  1.0536065013320357,\n",
       "  1.0533277326160007,\n",
       "  1.0529618748912104,\n",
       "  1.0537086725234985,\n",
       "  1.0528541759208396,\n",
       "  1.05267835104907,\n",
       "  1.0519134998321533,\n",
       "  1.0507204046955816,\n",
       "  1.0501638871652108,\n",
       "  1.0497546240135476,\n",
       "  1.0497422968899761,\n",
       "  1.0498603140866314,\n",
       "  1.0492480860816107,\n",
       "  1.0493130374837805,\n",
       "  1.0483195649252997,\n",
       "  1.0477055929325245,\n",
       "  1.0475598838594224,\n",
       "  1.047296126683553,\n",
       "  1.0468210688343755,\n",
       "  1.0462825033399794,\n",
       "  1.0463930147665519,\n",
       "  1.0460787525883428,\n",
       "  1.046123049877308,\n",
       "  1.0450015642024852,\n",
       "  1.0439530125370733,\n",
       "  1.0438285668690999,\n",
       "  1.043074855098018,\n",
       "  1.0429207660533764,\n",
       "  1.0425748471860532,\n",
       "  1.0417385675289013,\n",
       "  1.040856228934394,\n",
       "  1.040863655231617,\n",
       "  1.0410890932436343,\n",
       "  1.0410772385420624,\n",
       "  1.0403911846655387,\n",
       "  1.040090596234357,\n",
       "  1.0393099564093131,\n",
       "  1.0394119465792622,\n",
       "  1.0390983422597249,\n",
       "  1.0381905061227303,\n",
       "  1.0381669424198292,\n",
       "  1.0380188447457772,\n",
       "  1.0377138941376298,\n",
       "  1.036786366392065,\n",
       "  1.0365445834619027,\n",
       "  1.0363760745083843,\n",
       "  1.036163497854162,\n",
       "  1.035997536447313,\n",
       "  1.0353819220154374,\n",
       "  1.0345132130163688,\n",
       "  1.0341286173573248,\n",
       "  1.0338313888620447,\n",
       "  1.0340832074483235,\n",
       "  1.033631439562197,\n",
       "  1.0325351070474695,\n",
       "  1.0330588111171015,\n",
       "  1.032768761670148,\n",
       "  1.0323574631302446,\n",
       "  1.031783558704235,\n",
       "  1.0312100737183183,\n",
       "  1.031069481814349,\n",
       "  1.0301109375777069,\n",
       "  1.030167539914449,\n",
       "  1.0304400744261566,\n",
       "  1.0306955222730283,\n",
       "  1.0290072979750458,\n",
       "  1.0289590579492074,\n",
       "  1.0285002743756329,\n",
       "  1.0280654033025105,\n",
       "  1.0275217692057292,\n",
       "  1.0272022706490975,\n",
       "  1.027091626767759,\n",
       "  1.026536089402658,\n",
       "  1.0267439197610926,\n",
       "  1.025692794058058,\n",
       "  1.0257422526677449,\n",
       "  1.025492204560174,\n",
       "  1.0259147573400427,\n",
       "  1.0253936493838276,\n",
       "  1.0246225153958355,\n",
       "  1.0249568533014368,\n",
       "  1.0245459300500375,\n",
       "  1.0237424241171942,\n",
       "  1.0239930903470074,\n",
       "  1.023576091837,\n",
       "  1.0222959209371496,\n",
       "  1.0219903389612834,\n",
       "  1.0219790317394115,\n",
       "  1.0221896348176178,\n",
       "  1.0220140792705394,\n",
       "  1.0221656693352594,\n",
       "  1.0217743979560003,\n",
       "  1.0212954945034451,\n",
       "  1.0207319568704676,\n",
       "  1.0198068309713293,\n",
       "  1.019392035625599,\n",
       "  1.0194370128490307,\n",
       "  1.019664420021905,\n",
       "  1.019379147776851,\n",
       "  1.019042553725066,\n",
       "  1.0189809666739569,\n",
       "  1.0182769254401878,\n",
       "  1.018304016855028,\n",
       "  1.0185539634139449,\n",
       "  1.017340933835065,\n",
       "  1.016622499183372,\n",
       "  1.0167855245095712,\n",
       "  1.0170102031142623,\n",
       "  1.0171101446504947,\n",
       "  1.0160032422454268,\n",
       "  1.0157521080087732,\n",
       "  1.016357214362533,\n",
       "  1.016152059590375,\n",
       "  1.0154127677281697,\n",
       "  1.0147749450471666,\n",
       "  1.0148812929789226,\n",
       "  1.0142563493163497,\n",
       "  1.0142064800968877,\n",
       "  1.0136295866083216,\n",
       "  1.014111699881377,\n",
       "  1.0135472306498774,\n",
       "  1.0137313471900091,\n",
       "  1.0130721507249054,\n",
       "  1.0129604207144842,\n",
       "  1.0125033899589821,\n",
       "  1.012458222883719,\n",
       "  1.0121174918280706,\n",
       "  1.0118186385543257,\n",
       "  1.0114974666524816,\n",
       "  1.0116507962897971,\n",
       "  1.0109472672144573,\n",
       "  1.010720310387788,\n",
       "  1.0105342732535467,\n",
       "  1.0109861117822152,\n",
       "  1.0102996561262343,\n",
       "  1.0093122058444552,\n",
       "  1.0088780765180234,\n",
       "  1.008878266369855,\n",
       "  1.0088256376760978,\n",
       "  1.0084865578898676,\n",
       "  1.008240161118684,\n",
       "  1.0084683144534077,\n",
       "  1.0085559906782928,\n",
       "  1.0077751698317352,\n",
       "  1.007884392031917,\n",
       "  1.0073903445844297,\n",
       "  1.0070887450818662,\n",
       "  1.0069788032107883,\n",
       "  1.0063263266174882,\n",
       "  1.0064043645505552,\n",
       "  1.0061935362992462,\n",
       "  1.006116893556383,\n",
       "  1.0058382087283664,\n",
       "  1.0054960295006081,\n",
       "  1.005979197996634,\n",
       "  1.0057796195701316,\n",
       "  1.0054034568645336,\n",
       "  1.0047240301414773,\n",
       "  1.0043843852149115,\n",
       "  1.0041394719371088,\n",
       "  1.0041284163792927,\n",
       "  1.0044968437265467,\n",
       "  1.0037157182340268,\n",
       "  1.0030802973994501,\n",
       "  1.0033803913328383,\n",
       "  1.0030689725169428,\n",
       "  1.002666464558354,\n",
       "  1.003499600622389,\n",
       "  1.0027046027006927,\n",
       "  1.0028725730048285,\n",
       "  1.0036190218395658,\n",
       "  1.002310205388952,\n",
       "  1.00128761044255,\n",
       "  1.001358398684749,\n",
       "  1.0006997541145042,\n",
       "  1.0008369860825714,\n",
       "  1.0012366462636877,\n",
       "  1.0014937497951366,\n",
       "  1.0012373747649017,\n",
       "  1.000419916930022,\n",
       "  1.0007398349267465,\n",
       "  1.000586748123169,\n",
       "  1.0001666104352032,\n",
       "  0.9993686499419036,\n",
       "  0.9989639123280843,\n",
       "  0.9987364786642569,\n",
       "  0.9995919686776621,\n",
       "  0.9990924199422201,\n",
       "  0.9989883723082366,\n",
       "  0.998745114715011,\n",
       "  0.9980932297529997,\n",
       "  0.9977282197387131,\n",
       "  0.9978916821656404,\n",
       "  0.9971871817553485,\n",
       "  0.9973593685362074,\n",
       "  0.997374419812803,\n",
       "  0.997172823658696,\n",
       "  0.9962744271313703,\n",
       "  0.9974470094398216,\n",
       "  0.9971253562856603,\n",
       "  0.9968491571920889,\n",
       "  0.996605740653144,\n",
       "  0.9964059900354456,\n",
       "  0.9967222876018949,\n",
       "  0.995894158328021,\n",
       "  0.9957537606910423,\n",
       "  0.9957249429490831,\n",
       "  0.9956449491006357,\n",
       "  0.99488189485338,\n",
       "  0.9944522866496334,\n",
       "  0.9948641856511434,\n",
       "  0.9947187149966205,\n",
       "  0.994805411056236,\n",
       "  0.9941284479918303,\n",
       "  0.9941473581172802,\n",
       "  0.9935023343121564,\n",
       "  0.9933284962618792,\n",
       "  0.994039014533714,\n",
       "  0.9940892060597738,\n",
       "  0.9938778965561478,\n",
       "  0.9931181492628874,\n",
       "  0.9928616903446339,\n",
       "  0.9923475406788014,\n",
       "  0.9933475035208242,\n",
       "  0.9931779834959242,\n",
       "  0.9928316893400969,\n",
       "  0.9921703603532579,\n",
       "  0.991905446405764,\n",
       "  0.9921559625201755,\n",
       "  0.9918475195213601,\n",
       "  0.9912820745397497,\n",
       "  0.9911348775581077,\n",
       "  0.9910553384710241,\n",
       "  0.9911235173543295,\n",
       "  0.9906825268710101,\n",
       "  0.9912917834741098,\n",
       "  0.9909396127418235,\n",
       "  0.9901597146634702,\n",
       "  0.9902650824299565,\n",
       "  0.9908535392196091,\n",
       "  0.9904640736403288,\n",
       "  0.9901670173362449,\n",
       "  0.9901197177392466,\n",
       "  0.9895172913869222,\n",
       "  0.9896415427879051,\n",
       "  0.9893120968783343,\n",
       "  0.9895466610237404,\n",
       "  0.9892096607773392,\n",
       "  0.9886075214103416,\n",
       "  0.9886002893801089,\n",
       "  0.9885690212249756,\n",
       "  0.9883848737787317,\n",
       "  0.9881673918830024,\n",
       "  0.9884030907242386,\n",
       "  0.9881736702389188,\n",
       "  0.9882479950233742,\n",
       "  0.9877241717444526,\n",
       "  0.9875022614443744,\n",
       "  0.9883757167392306,\n",
       "  0.9879637294345431,\n",
       "  0.9875166945987277,\n",
       "  0.9874386610808196,\n",
       "  0.987084600660536,\n",
       "  0.9862793330793027,\n",
       "  0.9865742436161747,\n",
       "  0.9867001153804638,\n",
       "  0.9863663602758337,\n",
       "  0.9869670029039737,\n",
       "  0.9864119291305542,\n",
       "  0.9854000056231463,\n",
       "  0.9854377464011863,\n",
       "  0.9857744066803543,\n",
       "  0.9862204922570122,\n",
       "  0.9854312737782797,\n",
       "  0.9853283829159207,\n",
       "  0.985785064873872,\n",
       "  0.9856817060046725,\n",
       "  0.9857745435502794,\n",
       "  0.9854367132540103,\n",
       "  0.9851295285754733,\n",
       "  0.9851613353799891,\n",
       "  0.9845311509238349,\n",
       "  0.9843549066119723,\n",
       "  0.9840481457886873,\n",
       "  0.9839993671134666,\n",
       "  0.9843256429389671,\n",
       "  0.9844496470910532,\n",
       "  0.9846545811052676,\n",
       "  0.9839501822436297,\n",
       "  0.983524896480419,\n",
       "  0.9833581270994963,\n",
       "  0.983498939761409,\n",
       "  0.9835792691619308,\n",
       "  0.9837785826789008,\n",
       "  0.983789638236717,\n",
       "  0.9830806167037399,\n",
       "  0.9834117050524112,\n",
       "  0.9835311086089523,\n",
       "  0.98328462794975,\n",
       "  0.9830454102268925,\n",
       "  0.9829459852642484,\n",
       "  0.9824626622376619,\n",
       "  0.9821783657427188,\n",
       "  0.9825736769923458,\n",
       "  0.9827462302313911,\n",
       "  0.9822759650371693,\n",
       "  0.9812275767326355,\n",
       "  0.9813353573834455,\n",
       "  0.9818276829189725,\n",
       "  0.9818810997185884,\n",
       "  0.9823169730327748,\n",
       "  0.9815550843874613,\n",
       "  0.9814048343234592,\n",
       "  0.9806494756981179,\n",
       "  0.9812859738314593,\n",
       "  0.9807086984316508,\n",
       "  0.9811805619133843,\n",
       "  0.9809625501985904,\n",
       "  0.9807969552499277,\n",
       "  0.9810529262931259,\n",
       "  0.9812381598684523,\n",
       "  0.9806254130822641,\n",
       "  0.9799259878970958,\n",
       "  0.9802931171876413,\n",
       "  0.9802511356495045,\n",
       "  0.9803871137124521,\n",
       "  0.9805037732477542,\n",
       "  0.9803199745990612,\n",
       "  0.9808937642309401,\n",
       "  0.9797937781722458,\n",
       "  0.9794021072211089,\n",
       "  0.9803862152276216,\n",
       "  0.9792976004106028,\n",
       "  0.9789887247262178,\n",
       "  0.9790915670218291,\n",
       "  0.979239856755292,\n",
       "  0.9791701612649141,\n",
       "  0.9794643190171983,\n",
       "  0.9788931828958017,\n",
       "  0.9790650650306985,\n",
       "  0.9787999347404197,\n",
       "  0.9789001500165021,\n",
       "  0.9790677251639189,\n",
       "  0.9782446225484213,\n",
       "  0.9780814758053532,\n",
       "  0.9779809536757292,\n",
       "  0.9782924563796432,\n",
       "  0.9784588747554355,\n",
       "  0.9784811426092077,\n",
       "  0.9784755154892251,\n",
       "  0.9784580888571562,\n",
       "  0.9780286064854374,\n",
       "  0.9780202750806455,\n",
       "  0.9776412756354721,\n",
       "  0.9776972995864021,\n",
       "  0.9778461853663126,\n",
       "  0.9780424413857637,\n",
       "  0.9773522505053768,\n",
       "  0.97734135389328,\n",
       "  0.9771776729159884,\n",
       "  0.9774521059460111,\n",
       "  0.9771711826324463,\n",
       "  0.9768217691668758,\n",
       "  0.9770021306143867,\n",
       "  0.9768799675835503,\n",
       "  0.9761281830293161,\n",
       "  0.9767699925987808,\n",
       "  0.9764502291326169,\n",
       "  0.9767063127623664,\n",
       "  0.9759871429867215,\n",
       "  0.9764479641561155,\n",
       "  0.9759755068355136,\n",
       "  0.9761948099842778,\n",
       "  0.9762493283660324,\n",
       "  0.9759840921119407,\n",
       "  0.9764190095442312,\n",
       "  0.9760358112829702,\n",
       "  0.975867874092526,\n",
       "  0.9755093499466225,\n",
       "  0.9752722205939116,\n",
       "  0.9754300691463329,\n",
       "  0.9753242090896324,\n",
       "  0.9754665273207205,\n",
       "  0.9755009545220269,\n",
       "  0.9752991398175558,\n",
       "  0.9748030658121463,\n",
       "  0.97478304527424,\n",
       "  0.9751872839751067,\n",
       "  0.975840773847368,\n",
       "  0.9756929697813811,\n",
       "  0.9755840213210495,\n",
       "  0.9751192861133151,\n",
       "  0.9741701417499118,\n",
       "  0.9744561535340769,\n",
       "  0.9745423021139922,\n",
       "  0.974658363395267,\n",
       "  0.974403182665507,\n",
       "  0.9746293337256821,\n",
       "  0.9744997355673048,\n",
       "  0.9740173971211469,\n",
       "  0.973664934988375,\n",
       "  0.9740086065398322,\n",
       "  0.9747116521552757,\n",
       "  0.9740975013485661,\n",
       "  0.9738075446199488,\n",
       "  0.974142454288624,\n",
       "  0.9740991724861993,\n",
       "  0.9738383094469706,\n",
       "  0.9742124963689733,\n",
       "  0.9733935704937687,\n",
       "  0.9732124054873431,\n",
       "  0.9734705885251363,\n",
       "  0.9735423591401842,\n",
       "  0.9734572105937533,\n",
       "  0.973340180185106,\n",
       "  0.9732305186766165,\n",
       "  0.9730766172762271,\n",
       "  0.973238073013447,\n",
       "  0.9730548306747719,\n",
       "  0.9726788291224727,\n",
       "  0.9732194145520529,\n",
       "  0.9730780676559165,\n",
       "  0.972454532429024,\n",
       "  0.9727109383653711,\n",
       "  0.9727399702425357,\n",
       "  0.9727104593206335,\n",
       "  0.9723791524215981,\n",
       "  0.9721942058315983,\n",
       "  0.9725757351628056,\n",
       "  0.9721757924115216,\n",
       "  0.972183989153968,\n",
       "  0.9722982115215726,\n",
       "  0.9719957532706084,\n",
       "  0.9721501447536327,\n",
       "  0.9721946098186351,\n",
       "  0.9724874275702017,\n",
       "  0.9723714501769455,\n",
       "  0.9713244084958677,\n",
       "  0.9712981714142693,\n",
       "  0.9710796961077938,\n",
       "  0.9713715204486141,\n",
       "  0.9722040692965189,\n",
       "  0.9723120707052725,\n",
       "  0.9715675932389719,\n",
       "  0.9713231369301125,\n",
       "  0.9711989914929425,\n",
       "  0.9707774277086612,\n",
       "  0.9708581853795935,\n",
       "  0.9709063393098337,\n",
       "  0.9712292419539558,\n",
       "  0.9712702256661875,\n",
       "  0.9712591701083713,\n",
       "  0.9709637849419205,\n",
       "  0.9715209073490567,\n",
       "  0.9713283909691705,\n",
       "  0.9714667355572736,\n",
       "  0.9709632882365474,\n",
       "  0.9709389827869557,\n",
       "  0.9705681425553782,\n",
       "  0.970698599462156,\n",
       "  0.9709587936048154,\n",
       "  0.970628007694527,\n",
       "  0.9704648543287206,\n",
       "  0.9705484288710134,\n",
       "  0.9707778250729596,\n",
       "  0.9707265341723407,\n",
       "  0.9702437387572395,\n",
       "  0.9709182580312093,\n",
       "  0.9700095167866459,\n",
       "  0.9702336655722724,\n",
       "  0.9698213780367816,\n",
       "  0.9701822466320462,\n",
       "  0.9699817520600779,\n",
       "  0.9695421059926351,\n",
       "  0.970044802736353,\n",
       "  0.9697054138890019,\n",
       "  0.9693562035207395,\n",
       "  0.9698971112569174,\n",
       "  0.9704381315796463,\n",
       "  0.9699457199485214,\n",
       "  0.968588959287714,\n",
       "  0.9692798080267729,\n",
       "  0.9689376486672295,\n",
       "  0.9692918393346999,\n",
       "  0.9695894033820541,\n",
       "  0.9701968453548573,\n",
       "  0.9700083688453391,\n",
       "  0.9697736744527463,\n",
       "  0.9698928947801944,\n",
       "  0.9686815164707325,\n",
       "  0.9685179856088426,\n",
       "  0.9693424083568432,\n",
       "  0.9690534626996076,\n",
       "  0.9685907628801134,\n",
       "  0.9690093199412028,\n",
       "  0.9686808365362661,\n",
       "  0.9687169481206823,\n",
       "  0.9690951462145205,\n",
       "  0.9692601716076886,\n",
       "  0.9689338251396462,\n",
       "  0.9692233845039651,\n",
       "  0.9693753012904415,\n",
       "  0.9693735793784812,\n",
       "  0.9686115295798691,\n",
       "  0.9683331582281325,\n",
       "  0.9683396948708428,\n",
       "  0.9682029838915225,\n",
       "  0.9681571898636995,\n",
       "  0.9684725712846827,\n",
       "  0.9688910996472394,\n",
       "  0.9684361947907342,\n",
       "  0.9686076861840708,\n",
       "  0.9690225786632962,\n",
       "  0.9680381019910177,\n",
       "  0.9677655365731981,\n",
       "  0.9677078127861023,\n",
       "  0.9692964333075064,\n",
       "  0.9685931581038015,\n",
       "  0.9680725623060156,\n",
       "  0.9686267905765109,\n",
       "  0.968572771107709,\n",
       "  0.9682863729971426,\n",
       "  0.9672416735578466,\n",
       "  0.9676111318446972,\n",
       "  0.9676572967458654,\n",
       "  0.9681454742396319,\n",
       "  0.9680195230024832,\n",
       "  0.9675217315002724,\n",
       "  0.9680870859711258,\n",
       "  0.9681845947548195,\n",
       "  0.9670530645935623,\n",
       "  0.9671094285117255,\n",
       "  0.9677818572079694,\n",
       "  0.9673284844115928,\n",
       "  0.9673283916932566,\n",
       "  0.9675284050129078,\n",
       "  0.9677499289865847,\n",
       "  0.9676580164167616,\n",
       "  0.9674064340414824,\n",
       "  0.9672035773595175,\n",
       "  0.9670017339565136,\n",
       "  0.9671647813585069,\n",
       "  0.9676594999101427,\n",
       "  0.966733678623482,\n",
       "  0.9667121988755686,\n",
       "  0.9663736820220947,\n",
       "  0.9671573705143399,\n",
       "  0.9671527544657389,\n",
       "  0.9676009659413938,\n",
       "  0.9671052716396473,\n",
       "  0.966864596914362,\n",
       "  0.9669722539407236,\n",
       "  0.9675062740290606,\n",
       "  0.9668558946362248,\n",
       "  0.9667444847248219,\n",
       "  0.9666907412034494,\n",
       "  0.9665182563993666,\n",
       "  0.9669239631405583,\n",
       "  0.9663963671083804,\n",
       "  0.9659566857196666,\n",
       "  0.966496538232874,\n",
       "  0.9666240458135251,\n",
       "  0.9665835345232928,\n",
       "  0.9666845908871403,\n",
       "  0.9667507321746261,\n",
       "  0.9659037700405827,\n",
       "  0.9670041313877812,\n",
       "  0.9667022471074704,\n",
       "  0.9661942080215171,\n",
       "  0.9666807055473328,\n",
       "  0.966297655193894,\n",
       "  0.9666216417595193,\n",
       "  0.966698929115578,\n",
       "  0.9660063363887645,\n",
       "  0.9655603037940131,\n",
       "  0.9655127260420058,\n",
       "  0.9659167461925082,\n",
       "  0.9657954021736428,\n",
       "  0.9659535310886525,\n",
       "  0.9659666463180825,\n",
       "  0.9658567287303783,\n",
       "  0.9661885411651047,\n",
       "  0.9665916694535149,\n",
       "  0.9658411388044004,\n",
       "  0.9657539637000473,\n",
       "  0.9659157086301733,\n",
       "  0.9659494029151069,\n",
       "  0.9659151059609873,\n",
       "  0.9660800717495106,\n",
       "  0.9657962300159313,\n",
       "  0.9656792260982372,\n",
       "  0.9658570046778079,\n",
       "  0.9654547859121252,\n",
       "  0.9654334275810806,\n",
       "  0.9661855256115949,\n",
       "  0.9662244297839977,\n",
       "  0.9654346903165182,\n",
       "  0.9654560972143102,\n",
       "  0.9652248422304789,\n",
       "  0.9653849513442428,\n",
       "  0.9654471256114818,\n",
       "  0.9659692887906675,\n",
       "  0.9657907552189298,\n",
       "  0.9656881358888414,\n",
       "  0.9654405933839304,\n",
       "  0.9651579790645175,\n",
       "  0.9654833873112997,\n",
       "  0.9654236104753282,\n",
       "  0.9654961029688517,\n",
       "  0.9651373249513132,\n",
       "  0.9654565453529358,\n",
       "  0.9654330545001559,\n",
       "  0.9650901291105483,\n",
       "  0.9648632981159069,\n",
       "  0.9649160195280004,\n",
       "  0.9648625806525901,\n",
       "  0.9646717177497016,\n",
       "  0.9644702121063515,\n",
       "  0.964971003709016,\n",
       "  0.9646991403014572,\n",
       "  0.9650344186358981,\n",
       "  0.9651345919679712,\n",
       "  0.9649594337851913,\n",
       "  0.965330942913338,\n",
       "  0.9649690544163739,\n",
       "  0.9651910949636389,\n",
       "  0.9645685950915018,\n",
       "  0.9647661734510351,\n",
       "  0.9643226707423175,\n",
       "  0.9639432077054624,\n",
       "  0.9644350188749807,\n",
       "  0.9641777497750742,\n",
       "  0.9638871462256821,\n",
       "  0.9648527216028284,\n",
       "  0.9651820041515209,\n",
       "  0.9654643579765603,\n",
       "  0.9646499223179288,\n",
       "  0.9647595087687174,\n",
       "  0.9646462886421768,\n",
       "  0.9648517922118858,\n",
       "  0.9644973189742477,\n",
       "  0.964206666858108,\n",
       "  0.964212057767091,\n",
       "  0.9641275074746873,\n",
       "  0.9649248630912216,\n",
       "  0.9645356006092496,\n",
       "  0.9640081944289031,\n",
       "  0.9634719181943823,\n",
       "  0.9636994556144431,\n",
       "  0.9643968917705394,\n",
       "  0.9641917281680636,\n",
       "  0.9638411822142424,\n",
       "  0.9639840081886009,\n",
       "  0.963971855463805,\n",
       "  0.9641939688611914,\n",
       "  0.9641803238126967,\n",
       "  0.9644645033059297,\n",
       "  0.9641293817096286,\n",
       "  0.9642636996728403,\n",
       "  0.9639842929663481,\n",
       "  0.9644394781854417,\n",
       "  0.9640817664287709,\n",
       "  0.963718436382435,\n",
       "  0.9635356134838529,\n",
       "  0.9638961134133516,\n",
       "  0.9638149738311768,\n",
       "  0.9637383487489488,\n",
       "  0.9635940061675178,\n",
       "  0.9636017945077684,\n",
       "  0.9637724116996482,\n",
       "  0.9643156086957013,\n",
       "  0.9634827839003669,\n",
       "  0.9638558405416983,\n",
       "  0.9641705751419067,\n",
       "  0.9640746734760426,\n",
       "  0.9636694524023268,\n",
       "  0.963776221981755,\n",
       "  0.9639526031635426,\n",
       "  0.9638893339369032,\n",
       "  0.9630165718219899,\n",
       "  0.9634972810745239,\n",
       "  0.9637856218549941,\n",
       "  0.9637560932724564,\n",
       "  0.9640841241236087,\n",
       "  0.963591820663876,\n",
       "  0.9631676607661777,\n",
       "  0.9631747382658499,\n",
       "  0.9635505036071494,\n",
       "  0.9630083662492258,\n",
       "  0.9622307000336824,\n",
       "  0.9634521824342234,\n",
       "  0.9633307832258718,\n",
       "  0.9629545300095169,\n",
       "  0.9633136435791299,\n",
       "  0.9631500486974363,\n",
       "  0.9628525464623062,\n",
       "  0.9632177374981068,\n",
       "  0.9633624001785561,\n",
       "  0.9636530611250136,\n",
       "  ...]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "hsNO9nnXQBvP",
    "outputId": "1626def6-94c7-4a87-9447-d939f827c8eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(model_loss_record, title='deep model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "3iZTVn5WQFpX",
    "outputId": "a2d5e118-559d-45c6-b644-6792af54663d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "del model\n",
    "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
    "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
    "model.load_state_dict(ckpt)\n",
    "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQikz3IPiyPf"
   },
   "source": [
    "# **Testing**\n",
    "The predictions of your model on testing set will be stored at `pred.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8cTuQjQQOon",
    "outputId": "6bc5de07-4c5a-4e87-9ae3-d09f539c5f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to pred.csv\n"
     ]
    }
   ],
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    print('Saving results to {}'.format(file))\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])\n",
    "\n",
    "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
    "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPuibV8rME8Y2Er3TVnCm93",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ML2021Spring - HW1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
